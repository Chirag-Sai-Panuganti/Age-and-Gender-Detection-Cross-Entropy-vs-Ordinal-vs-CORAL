{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec510b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T08:53:29.652435Z",
     "iopub.status.busy": "2023-08-08T08:53:29.651933Z",
     "iopub.status.idle": "2023-08-08T08:53:32.174247Z",
     "shell.execute_reply": "2023-08-08T08:53:32.173160Z"
    },
    "papermill": {
     "duration": 2.531119,
     "end_time": "2023-08-08T08:53:32.177183",
     "exception": false,
     "start_time": "2023-08-08T08:53:29.646064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import sys\n",
    "import torchvision.models as models\n",
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79ea192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T08:53:32.185851Z",
     "iopub.status.busy": "2023-08-08T08:53:32.184636Z",
     "iopub.status.idle": "2023-08-08T08:53:32.266520Z",
     "shell.execute_reply": "2023-08-08T08:53:32.265383Z"
    },
    "papermill": {
     "duration": 0.088789,
     "end_time": "2023-08-08T08:53:32.269275",
     "exception": false,
     "start_time": "2023-08-08T08:53:32.180486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.0\n",
      "CUDA device available: True\n",
      "Using CUDA device: cuda:0\n",
      "Random Seed: 0\n",
      "Output Path: ./CE-CNN\n",
      "Script: /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\n"
     ]
    }
   ],
   "source": [
    "# File Paths\n",
    "TRAIN_CSV_PATH = \"/kaggle/input/utkface/Dataset/Index/Train.csv\"\n",
    "VALID_CSV_PATH = \"/kaggle/input/utkface/Dataset/Index/Validation.csv\"\n",
    "TEST_CSV_PATH = \"/kaggle/input/utkface/Dataset/Index/Test.csv\"\n",
    "IMAGE_PATH = \"/kaggle/input/utkface/Dataset/Images\"\n",
    "\n",
    "# Global Variables\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--cuda',\n",
    "                    type=int,\n",
    "                    default=0)\n",
    "\n",
    "parser.add_argument('--seed',\n",
    "                    type=int,\n",
    "                    default=0)\n",
    "\n",
    "parser.add_argument('--numworkers',\n",
    "                    type=int,\n",
    "                    default=2)\n",
    "\n",
    "parser.add_argument('--outpath',\n",
    "                    type=str,\n",
    "                    required=False,default='./CE-CNN')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "NUM_WORKERS = args.numworkers\n",
    "\n",
    "if args.cuda >= 0:\n",
    "    DEVICE = torch.device(\"cuda:%d\" % args.cuda)\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "if args.seed == -1:\n",
    "    RANDOM_SEED = None\n",
    "else:\n",
    "    RANDOM_SEED = args.seed\n",
    "\n",
    "Path = args.outpath\n",
    "if not os.path.exists(Path):\n",
    "  os.mkdir(Path)\n",
    "LOGFILE = os.path.join(Path, 'Training.log')\n",
    "TEST_PREDICTIONS1 = os.path.join(Path, 'Age.log')\n",
    "TEST_PREDICTIONS2 = os.path.join(Path, 'Gender.log')\n",
    "TEST_ALLPROBAS = os.path.join(Path, 'Test_allprobas.tensor')\n",
    "\n",
    "# Logging\n",
    "header = []\n",
    "\n",
    "header.append('PyTorch Version: %s' % torch.__version__)\n",
    "header.append('CUDA device available: %s' % torch.cuda.is_available())\n",
    "header.append('Using CUDA device: %s' % DEVICE)\n",
    "header.append('Random Seed: %s' % RANDOM_SEED)\n",
    "header.append('Output Path: %s' % Path)\n",
    "header.append('Script: %s' % sys.argv[0])\n",
    "\n",
    "with open(LOGFILE, 'w') as f:\n",
    "    for entry in header:\n",
    "        print(entry)\n",
    "        f.write('%s\\n' % entry)\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9af1ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T08:53:32.276869Z",
     "iopub.status.busy": "2023-08-08T08:53:32.276509Z",
     "iopub.status.idle": "2023-08-08T08:53:32.461158Z",
     "shell.execute_reply": "2023-08-08T08:53:32.460042Z"
    },
    "papermill": {
     "duration": 0.191586,
     "end_time": "2023-08-08T08:53:32.463987",
     "exception": false,
     "start_time": "2023-08-08T08:53:32.272401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 75\n",
    "BATCH_SIZE = 256\n",
    "GRAYSCALE = False\n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "ages = df['age'].values\n",
    "gender = df['gender'].values\n",
    "del df\n",
    "ages = torch.tensor(ages, dtype=torch.float)\n",
    "gender = torch.tensor(gender, dtype=torch.float)\n",
    "\n",
    "# Data Loader to send Images and corresponding Labels into model\n",
    "class UTKFace(Dataset):\n",
    "    def __init__(self,\n",
    "                 csv_path, img_dir, transform=None):\n",
    "\n",
    "        df = pd.read_csv(csv_path,)\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.img_names =df.iloc[:,3]\n",
    "        self.y = df[\"age\"].values\n",
    "        self.z = df[\"gender\"].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label1 = self.y[index]\n",
    "        label2 = self.z[index]\n",
    "        \n",
    "        return img, label1, label2\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "\n",
    "custom_transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                       transforms.RandomCrop((120, 120)),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "train_dataset = UTKFace(csv_path=TRAIN_CSV_PATH,\n",
    "                              img_dir=os.path.join(IMAGE_PATH,\"Train\"),\n",
    "                              transform=custom_transform)\n",
    "\n",
    "custom_transform2 = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                       transforms.CenterCrop((120, 120)),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "test_dataset = UTKFace(csv_path=TEST_CSV_PATH,\n",
    "                             img_dir=os.path.join(IMAGE_PATH,\"Test\"),\n",
    "                             transform=custom_transform2)\n",
    "\n",
    "valid_dataset = UTKFace(csv_path=VALID_CSV_PATH,\n",
    "                              img_dir=os.path.join(IMAGE_PATH,\"Validation\"),\n",
    "                              transform=custom_transform2)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=NUM_WORKERS)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=NUM_WORKERS)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3e5c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T08:53:32.472056Z",
     "iopub.status.busy": "2023-08-08T08:53:32.471421Z",
     "iopub.status.idle": "2023-08-08T08:53:32.494168Z",
     "shell.execute_reply": "2023-08-08T08:53:32.493049Z"
    },
    "papermill": {
     "duration": 0.029334,
     "end_time": "2023-08-08T08:53:32.496581",
     "exception": false,
     "start_time": "2023-08-08T08:53:32.467247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RESNET-34 Architecture\n",
    "class resnet(ResNet):\n",
    "    def __init__(self,block,layers,num_classes, grayscale):\n",
    "        self.num_classes=117\n",
    "        self.block=BasicBlock\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(4)\n",
    "        self.fc1 = nn.Linear(512, 117, bias=True)                            # Bias is True\n",
    "        self.fc2 = nn.Linear(512, 2, bias=True)                             # Bias is True\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits1 = self.fc1(x)\n",
    "        logits2 = self.fc2(x)\n",
    "        probas1 = F.softmax(logits1,dim=1)                                    # Softmax Activation Function\n",
    "        probas2 = F.softmax(logits2, dim=1)\n",
    "        return logits1, logits2, probas1, probas2\n",
    "\n",
    "def resnet34(num_classes,grayscale):\n",
    "    model=resnet(BasicBlock,\n",
    "                   layers=[3, 4, 6, 3],\n",
    "                   num_classes=num_classes,\n",
    "                   grayscale=grayscale)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff2841ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T08:53:32.504268Z",
     "iopub.status.busy": "2023-08-08T08:53:32.503969Z",
     "iopub.status.idle": "2023-08-08T09:35:41.147491Z",
     "shell.execute_reply": "2023-08-08T09:35:41.144739Z"
    },
    "papermill": {
     "duration": 2528.701634,
     "end_time": "2023-08-08T09:35:41.201286",
     "exception": false,
     "start_time": "2023-08-08T08:53:32.499652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/075 | Batch 0000/0071 | Cost: 5.7633\n",
      "Epoch: 001/075 | Batch 0010/0071 | Cost: 4.8018\n",
      "Epoch: 001/075 | Batch 0020/0071 | Cost: 4.3918\n",
      "Epoch: 001/075 | Batch 0030/0071 | Cost: 4.2558\n",
      "Epoch: 001/075 | Batch 0040/0071 | Cost: 4.0470\n",
      "Epoch: 001/075 | Batch 0050/0071 | Cost: 4.1743\n",
      "Epoch: 001/075 | Batch 0060/0071 | Cost: 4.1161\n",
      "Epoch: 001/075 | Batch 0070/0071 | Cost: 3.9647\n",
      "MAE/RMSE: | Current Valid: 11.71/18.10/73.83 Ep. 0 | Best Valid : 11.71/18.10/73.83 Ep. 0\n",
      "Time elapsed: 1.11 min\n",
      "Epoch: 002/075 | Batch 0000/0071 | Cost: 3.8676\n",
      "Epoch: 002/075 | Batch 0010/0071 | Cost: 4.0713\n",
      "Epoch: 002/075 | Batch 0020/0071 | Cost: 3.9821\n",
      "Epoch: 002/075 | Batch 0030/0071 | Cost: 3.9482\n",
      "Epoch: 002/075 | Batch 0040/0071 | Cost: 3.8871\n",
      "Epoch: 002/075 | Batch 0050/0071 | Cost: 3.6667\n",
      "Epoch: 002/075 | Batch 0060/0071 | Cost: 3.7830\n",
      "Epoch: 002/075 | Batch 0070/0071 | Cost: 3.8416\n",
      "MAE/RMSE: | Current Valid: 13.04/20.69/83.46 Ep. 1 | Best Valid : 11.71/18.10/73.83 Ep. 0\n",
      "Time elapsed: 1.65 min\n",
      "Epoch: 003/075 | Batch 0000/0071 | Cost: 3.6875\n",
      "Epoch: 003/075 | Batch 0010/0071 | Cost: 3.4896\n",
      "Epoch: 003/075 | Batch 0020/0071 | Cost: 3.7625\n",
      "Epoch: 003/075 | Batch 0030/0071 | Cost: 3.6782\n",
      "Epoch: 003/075 | Batch 0040/0071 | Cost: 3.4421\n",
      "Epoch: 003/075 | Batch 0050/0071 | Cost: 3.6545\n",
      "Epoch: 003/075 | Batch 0060/0071 | Cost: 3.5685\n",
      "Epoch: 003/075 | Batch 0070/0071 | Cost: 3.4929\n",
      "MAE/RMSE: | Current Valid: 9.91/15.15/72.08 Ep. 2 | Best Valid : 9.91/15.15/72.08 Ep. 2\n",
      "Time elapsed: 2.20 min\n",
      "Epoch: 004/075 | Batch 0000/0071 | Cost: 3.4685\n",
      "Epoch: 004/075 | Batch 0010/0071 | Cost: 3.5354\n",
      "Epoch: 004/075 | Batch 0020/0071 | Cost: 3.6061\n",
      "Epoch: 004/075 | Batch 0030/0071 | Cost: 3.4843\n",
      "Epoch: 004/075 | Batch 0040/0071 | Cost: 3.4004\n",
      "Epoch: 004/075 | Batch 0050/0071 | Cost: 3.4184\n",
      "Epoch: 004/075 | Batch 0060/0071 | Cost: 3.5175\n",
      "Epoch: 004/075 | Batch 0070/0071 | Cost: 3.3423\n",
      "MAE/RMSE: | Current Valid: 9.40/13.92/85.12 Ep. 3 | Best Valid : 9.40/13.92/85.12 Ep. 3\n",
      "Time elapsed: 2.77 min\n",
      "Epoch: 005/075 | Batch 0000/0071 | Cost: 3.3486\n",
      "Epoch: 005/075 | Batch 0010/0071 | Cost: 3.2846\n",
      "Epoch: 005/075 | Batch 0020/0071 | Cost: 3.2966\n",
      "Epoch: 005/075 | Batch 0030/0071 | Cost: 3.4854\n",
      "Epoch: 005/075 | Batch 0040/0071 | Cost: 3.4236\n",
      "Epoch: 005/075 | Batch 0050/0071 | Cost: 3.4003\n",
      "Epoch: 005/075 | Batch 0060/0071 | Cost: 3.4025\n",
      "Epoch: 005/075 | Batch 0070/0071 | Cost: 3.3573\n",
      "MAE/RMSE: | Current Valid: 8.24/12.99/86.39 Ep. 4 | Best Valid : 8.24/12.99/86.39 Ep. 4\n",
      "Time elapsed: 3.37 min\n",
      "Epoch: 006/075 | Batch 0000/0071 | Cost: 3.3427\n",
      "Epoch: 006/075 | Batch 0010/0071 | Cost: 3.3509\n",
      "Epoch: 006/075 | Batch 0020/0071 | Cost: 3.2073\n",
      "Epoch: 006/075 | Batch 0030/0071 | Cost: 3.2452\n",
      "Epoch: 006/075 | Batch 0040/0071 | Cost: 3.4006\n",
      "Epoch: 006/075 | Batch 0050/0071 | Cost: 3.1620\n",
      "Epoch: 006/075 | Batch 0060/0071 | Cost: 3.3599\n",
      "Epoch: 006/075 | Batch 0070/0071 | Cost: 3.2870\n",
      "MAE/RMSE: | Current Valid: 7.42/11.50/85.51 Ep. 5 | Best Valid : 7.42/11.50/85.51 Ep. 5\n",
      "Time elapsed: 3.92 min\n",
      "Epoch: 007/075 | Batch 0000/0071 | Cost: 3.2433\n",
      "Epoch: 007/075 | Batch 0010/0071 | Cost: 3.1026\n",
      "Epoch: 007/075 | Batch 0020/0071 | Cost: 3.2203\n",
      "Epoch: 007/075 | Batch 0030/0071 | Cost: 3.1965\n",
      "Epoch: 007/075 | Batch 0040/0071 | Cost: 3.1534\n",
      "Epoch: 007/075 | Batch 0050/0071 | Cost: 3.0931\n",
      "Epoch: 007/075 | Batch 0060/0071 | Cost: 3.1967\n",
      "Epoch: 007/075 | Batch 0070/0071 | Cost: 3.2476\n",
      "MAE/RMSE: | Current Valid: 7.65/12.67/87.00 Ep. 6 | Best Valid : 7.42/11.50/85.51 Ep. 5\n",
      "Time elapsed: 4.51 min\n",
      "Epoch: 008/075 | Batch 0000/0071 | Cost: 3.0960\n",
      "Epoch: 008/075 | Batch 0010/0071 | Cost: 2.9663\n",
      "Epoch: 008/075 | Batch 0020/0071 | Cost: 2.9485\n",
      "Epoch: 008/075 | Batch 0030/0071 | Cost: 3.1371\n",
      "Epoch: 008/075 | Batch 0040/0071 | Cost: 3.3220\n",
      "Epoch: 008/075 | Batch 0050/0071 | Cost: 3.0615\n",
      "Epoch: 008/075 | Batch 0060/0071 | Cost: 3.0362\n",
      "Epoch: 008/075 | Batch 0070/0071 | Cost: 3.0881\n",
      "MAE/RMSE: | Current Valid: 7.86/12.40/83.94 Ep. 7 | Best Valid : 7.42/11.50/85.51 Ep. 5\n",
      "Time elapsed: 5.11 min\n",
      "Epoch: 009/075 | Batch 0000/0071 | Cost: 3.0104\n",
      "Epoch: 009/075 | Batch 0010/0071 | Cost: 2.9864\n",
      "Epoch: 009/075 | Batch 0020/0071 | Cost: 2.9193\n",
      "Epoch: 009/075 | Batch 0030/0071 | Cost: 3.0444\n",
      "Epoch: 009/075 | Batch 0040/0071 | Cost: 3.0427\n",
      "Epoch: 009/075 | Batch 0050/0071 | Cost: 3.0131\n",
      "Epoch: 009/075 | Batch 0060/0071 | Cost: 3.2343\n",
      "Epoch: 009/075 | Batch 0070/0071 | Cost: 2.9876\n",
      "MAE/RMSE: | Current Valid: 6.92/10.62/88.58 Ep. 8 | Best Valid : 6.92/10.62/88.58 Ep. 8\n",
      "Time elapsed: 5.69 min\n",
      "Epoch: 010/075 | Batch 0000/0071 | Cost: 2.9779\n",
      "Epoch: 010/075 | Batch 0010/0071 | Cost: 2.9107\n",
      "Epoch: 010/075 | Batch 0020/0071 | Cost: 2.8127\n",
      "Epoch: 010/075 | Batch 0030/0071 | Cost: 2.7914\n",
      "Epoch: 010/075 | Batch 0040/0071 | Cost: 2.8215\n",
      "Epoch: 010/075 | Batch 0050/0071 | Cost: 2.9480\n",
      "Epoch: 010/075 | Batch 0060/0071 | Cost: 2.9418\n",
      "Epoch: 010/075 | Batch 0070/0071 | Cost: 2.8115\n",
      "MAE/RMSE: | Current Valid: 11.13/17.87/86.17 Ep. 9 | Best Valid : 6.92/10.62/88.58 Ep. 8\n",
      "Time elapsed: 6.26 min\n",
      "Epoch: 011/075 | Batch 0000/0071 | Cost: 2.6916\n",
      "Epoch: 011/075 | Batch 0010/0071 | Cost: 2.9773\n",
      "Epoch: 011/075 | Batch 0020/0071 | Cost: 2.8457\n",
      "Epoch: 011/075 | Batch 0030/0071 | Cost: 2.7726\n",
      "Epoch: 011/075 | Batch 0040/0071 | Cost: 2.8228\n",
      "Epoch: 011/075 | Batch 0050/0071 | Cost: 3.0187\n",
      "Epoch: 011/075 | Batch 0060/0071 | Cost: 2.9607\n",
      "Epoch: 011/075 | Batch 0070/0071 | Cost: 2.8814\n",
      "MAE/RMSE: | Current Valid: 6.99/10.66/88.84 Ep. 10 | Best Valid : 6.92/10.62/88.58 Ep. 8\n",
      "Time elapsed: 6.84 min\n",
      "Epoch: 012/075 | Batch 0000/0071 | Cost: 2.7006\n",
      "Epoch: 012/075 | Batch 0010/0071 | Cost: 2.7443\n",
      "Epoch: 012/075 | Batch 0020/0071 | Cost: 2.6701\n",
      "Epoch: 012/075 | Batch 0030/0071 | Cost: 2.6959\n",
      "Epoch: 012/075 | Batch 0040/0071 | Cost: 2.6467\n",
      "Epoch: 012/075 | Batch 0050/0071 | Cost: 2.7391\n",
      "Epoch: 012/075 | Batch 0060/0071 | Cost: 2.8393\n",
      "Epoch: 012/075 | Batch 0070/0071 | Cost: 2.7649\n",
      "MAE/RMSE: | Current Valid: 6.73/9.76/85.82 Ep. 11 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 7.44 min\n",
      "Epoch: 013/075 | Batch 0000/0071 | Cost: 2.5825\n",
      "Epoch: 013/075 | Batch 0010/0071 | Cost: 2.4540\n",
      "Epoch: 013/075 | Batch 0020/0071 | Cost: 2.5551\n",
      "Epoch: 013/075 | Batch 0030/0071 | Cost: 2.5412\n",
      "Epoch: 013/075 | Batch 0040/0071 | Cost: 2.5426\n",
      "Epoch: 013/075 | Batch 0050/0071 | Cost: 2.8230\n",
      "Epoch: 013/075 | Batch 0060/0071 | Cost: 2.6609\n",
      "Epoch: 013/075 | Batch 0070/0071 | Cost: 2.8843\n",
      "MAE/RMSE: | Current Valid: 7.92/12.33/85.78 Ep. 12 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 8.05 min\n",
      "Epoch: 014/075 | Batch 0000/0071 | Cost: 2.3983\n",
      "Epoch: 014/075 | Batch 0010/0071 | Cost: 2.3594\n",
      "Epoch: 014/075 | Batch 0020/0071 | Cost: 2.4281\n",
      "Epoch: 014/075 | Batch 0030/0071 | Cost: 2.4649\n",
      "Epoch: 014/075 | Batch 0040/0071 | Cost: 2.4428\n",
      "Epoch: 014/075 | Batch 0050/0071 | Cost: 2.6139\n",
      "Epoch: 014/075 | Batch 0060/0071 | Cost: 2.4449\n",
      "Epoch: 014/075 | Batch 0070/0071 | Cost: 2.5847\n",
      "MAE/RMSE: | Current Valid: 7.13/11.05/87.70 Ep. 13 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 8.69 min\n",
      "Epoch: 015/075 | Batch 0000/0071 | Cost: 2.1934\n",
      "Epoch: 015/075 | Batch 0010/0071 | Cost: 2.1853\n",
      "Epoch: 015/075 | Batch 0020/0071 | Cost: 2.4169\n",
      "Epoch: 015/075 | Batch 0030/0071 | Cost: 2.2711\n",
      "Epoch: 015/075 | Batch 0040/0071 | Cost: 2.3746\n",
      "Epoch: 015/075 | Batch 0050/0071 | Cost: 2.3848\n",
      "Epoch: 015/075 | Batch 0060/0071 | Cost: 2.4394\n",
      "Epoch: 015/075 | Batch 0070/0071 | Cost: 2.4384\n",
      "MAE/RMSE: | Current Valid: 7.54/11.26/86.87 Ep. 14 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 9.26 min\n",
      "Epoch: 016/075 | Batch 0000/0071 | Cost: 2.0970\n",
      "Epoch: 016/075 | Batch 0010/0071 | Cost: 2.0498\n",
      "Epoch: 016/075 | Batch 0020/0071 | Cost: 2.1098\n",
      "Epoch: 016/075 | Batch 0030/0071 | Cost: 2.1201\n",
      "Epoch: 016/075 | Batch 0040/0071 | Cost: 2.1639\n",
      "Epoch: 016/075 | Batch 0050/0071 | Cost: 2.4590\n",
      "Epoch: 016/075 | Batch 0060/0071 | Cost: 2.2785\n",
      "Epoch: 016/075 | Batch 0070/0071 | Cost: 2.2802\n",
      "MAE/RMSE: | Current Valid: 7.76/11.51/88.36 Ep. 15 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 9.83 min\n",
      "Epoch: 017/075 | Batch 0000/0071 | Cost: 1.8784\n",
      "Epoch: 017/075 | Batch 0010/0071 | Cost: 1.8901\n",
      "Epoch: 017/075 | Batch 0020/0071 | Cost: 1.8571\n",
      "Epoch: 017/075 | Batch 0030/0071 | Cost: 1.9670\n",
      "Epoch: 017/075 | Batch 0040/0071 | Cost: 2.0627\n",
      "Epoch: 017/075 | Batch 0050/0071 | Cost: 2.0424\n",
      "Epoch: 017/075 | Batch 0060/0071 | Cost: 2.1707\n",
      "Epoch: 017/075 | Batch 0070/0071 | Cost: 2.3136\n",
      "MAE/RMSE: | Current Valid: 11.56/18.39/86.04 Ep. 16 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 10.45 min\n",
      "Epoch: 018/075 | Batch 0000/0071 | Cost: 1.5519\n",
      "Epoch: 018/075 | Batch 0010/0071 | Cost: 1.7075\n",
      "Epoch: 018/075 | Batch 0020/0071 | Cost: 1.6281\n",
      "Epoch: 018/075 | Batch 0030/0071 | Cost: 1.6724\n",
      "Epoch: 018/075 | Batch 0040/0071 | Cost: 1.6633\n",
      "Epoch: 018/075 | Batch 0050/0071 | Cost: 1.9020\n",
      "Epoch: 018/075 | Batch 0060/0071 | Cost: 2.1535\n",
      "Epoch: 018/075 | Batch 0070/0071 | Cost: 1.9300\n",
      "MAE/RMSE: | Current Valid: 8.76/14.38/89.06 Ep. 17 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 11.05 min\n",
      "Epoch: 019/075 | Batch 0000/0071 | Cost: 1.2717\n",
      "Epoch: 019/075 | Batch 0010/0071 | Cost: 1.3438\n",
      "Epoch: 019/075 | Batch 0020/0071 | Cost: 1.3643\n",
      "Epoch: 019/075 | Batch 0030/0071 | Cost: 1.3973\n",
      "Epoch: 019/075 | Batch 0040/0071 | Cost: 1.3824\n",
      "Epoch: 019/075 | Batch 0050/0071 | Cost: 1.7234\n",
      "Epoch: 019/075 | Batch 0060/0071 | Cost: 1.7558\n",
      "Epoch: 019/075 | Batch 0070/0071 | Cost: 1.7293\n",
      "MAE/RMSE: | Current Valid: 7.39/10.80/88.71 Ep. 18 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 11.61 min\n",
      "Epoch: 020/075 | Batch 0000/0071 | Cost: 1.1725\n",
      "Epoch: 020/075 | Batch 0010/0071 | Cost: 1.3393\n",
      "Epoch: 020/075 | Batch 0020/0071 | Cost: 1.0605\n",
      "Epoch: 020/075 | Batch 0030/0071 | Cost: 1.2779\n",
      "Epoch: 020/075 | Batch 0040/0071 | Cost: 1.2521\n",
      "Epoch: 020/075 | Batch 0050/0071 | Cost: 1.4399\n",
      "Epoch: 020/075 | Batch 0060/0071 | Cost: 1.4535\n",
      "Epoch: 020/075 | Batch 0070/0071 | Cost: 1.3524\n",
      "MAE/RMSE: | Current Valid: 7.69/11.89/86.78 Ep. 19 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 12.20 min\n",
      "Epoch: 021/075 | Batch 0000/0071 | Cost: 1.0168\n",
      "Epoch: 021/075 | Batch 0010/0071 | Cost: 1.1394\n",
      "Epoch: 021/075 | Batch 0020/0071 | Cost: 0.9030\n",
      "Epoch: 021/075 | Batch 0030/0071 | Cost: 1.0117\n",
      "Epoch: 021/075 | Batch 0040/0071 | Cost: 1.1828\n",
      "Epoch: 021/075 | Batch 0050/0071 | Cost: 1.0722\n",
      "Epoch: 021/075 | Batch 0060/0071 | Cost: 1.1989\n",
      "Epoch: 021/075 | Batch 0070/0071 | Cost: 1.2834\n",
      "MAE/RMSE: | Current Valid: 7.91/12.91/88.32 Ep. 20 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 12.74 min\n",
      "Epoch: 022/075 | Batch 0000/0071 | Cost: 0.8294\n",
      "Epoch: 022/075 | Batch 0010/0071 | Cost: 0.8480\n",
      "Epoch: 022/075 | Batch 0020/0071 | Cost: 0.8635\n",
      "Epoch: 022/075 | Batch 0030/0071 | Cost: 0.9215\n",
      "Epoch: 022/075 | Batch 0040/0071 | Cost: 0.8886\n",
      "Epoch: 022/075 | Batch 0050/0071 | Cost: 0.9421\n",
      "Epoch: 022/075 | Batch 0060/0071 | Cost: 0.9676\n",
      "Epoch: 022/075 | Batch 0070/0071 | Cost: 1.0329\n",
      "MAE/RMSE: | Current Valid: 7.26/10.89/87.05 Ep. 21 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 13.31 min\n",
      "Epoch: 023/075 | Batch 0000/0071 | Cost: 0.6147\n",
      "Epoch: 023/075 | Batch 0010/0071 | Cost: 0.8433\n",
      "Epoch: 023/075 | Batch 0020/0071 | Cost: 0.7480\n",
      "Epoch: 023/075 | Batch 0030/0071 | Cost: 0.7323\n",
      "Epoch: 023/075 | Batch 0040/0071 | Cost: 0.6794\n",
      "Epoch: 023/075 | Batch 0050/0071 | Cost: 0.8285\n",
      "Epoch: 023/075 | Batch 0060/0071 | Cost: 0.8272\n",
      "Epoch: 023/075 | Batch 0070/0071 | Cost: 0.7346\n",
      "MAE/RMSE: | Current Valid: 8.64/13.21/87.18 Ep. 22 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 13.87 min\n",
      "Epoch: 024/075 | Batch 0000/0071 | Cost: 0.5125\n",
      "Epoch: 024/075 | Batch 0010/0071 | Cost: 0.5467\n",
      "Epoch: 024/075 | Batch 0020/0071 | Cost: 0.6272\n",
      "Epoch: 024/075 | Batch 0030/0071 | Cost: 0.5384\n",
      "Epoch: 024/075 | Batch 0040/0071 | Cost: 0.7000\n",
      "Epoch: 024/075 | Batch 0050/0071 | Cost: 0.9050\n",
      "Epoch: 024/075 | Batch 0060/0071 | Cost: 0.6551\n",
      "Epoch: 024/075 | Batch 0070/0071 | Cost: 0.6935\n",
      "MAE/RMSE: | Current Valid: 7.48/11.44/86.91 Ep. 23 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 14.42 min\n",
      "Epoch: 025/075 | Batch 0000/0071 | Cost: 0.5491\n",
      "Epoch: 025/075 | Batch 0010/0071 | Cost: 0.4298\n",
      "Epoch: 025/075 | Batch 0020/0071 | Cost: 0.5147\n",
      "Epoch: 025/075 | Batch 0030/0071 | Cost: 0.4828\n",
      "Epoch: 025/075 | Batch 0040/0071 | Cost: 0.5626\n",
      "Epoch: 025/075 | Batch 0050/0071 | Cost: 0.5952\n",
      "Epoch: 025/075 | Batch 0060/0071 | Cost: 0.6051\n",
      "Epoch: 025/075 | Batch 0070/0071 | Cost: 0.6345\n",
      "MAE/RMSE: | Current Valid: 7.21/10.87/88.23 Ep. 24 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 14.97 min\n",
      "Epoch: 026/075 | Batch 0000/0071 | Cost: 0.4599\n",
      "Epoch: 026/075 | Batch 0010/0071 | Cost: 0.3528\n",
      "Epoch: 026/075 | Batch 0020/0071 | Cost: 0.4391\n",
      "Epoch: 026/075 | Batch 0030/0071 | Cost: 0.5230\n",
      "Epoch: 026/075 | Batch 0040/0071 | Cost: 0.5611\n",
      "Epoch: 026/075 | Batch 0050/0071 | Cost: 0.5355\n",
      "Epoch: 026/075 | Batch 0060/0071 | Cost: 0.5386\n",
      "Epoch: 026/075 | Batch 0070/0071 | Cost: 0.4763\n",
      "MAE/RMSE: | Current Valid: 20.34/28.80/84.42 Ep. 25 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 15.52 min\n",
      "Epoch: 027/075 | Batch 0000/0071 | Cost: 0.5068\n",
      "Epoch: 027/075 | Batch 0010/0071 | Cost: 0.4899\n",
      "Epoch: 027/075 | Batch 0020/0071 | Cost: 0.2839\n",
      "Epoch: 027/075 | Batch 0030/0071 | Cost: 0.4192\n",
      "Epoch: 027/075 | Batch 0040/0071 | Cost: 0.4302\n",
      "Epoch: 027/075 | Batch 0050/0071 | Cost: 0.4331\n",
      "Epoch: 027/075 | Batch 0060/0071 | Cost: 0.3876\n",
      "Epoch: 027/075 | Batch 0070/0071 | Cost: 0.5071\n",
      "MAE/RMSE: | Current Valid: 7.38/11.06/88.84 Ep. 26 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 16.07 min\n",
      "Epoch: 028/075 | Batch 0000/0071 | Cost: 0.2866\n",
      "Epoch: 028/075 | Batch 0010/0071 | Cost: 0.3424\n",
      "Epoch: 028/075 | Batch 0020/0071 | Cost: 0.3672\n",
      "Epoch: 028/075 | Batch 0030/0071 | Cost: 0.4108\n",
      "Epoch: 028/075 | Batch 0040/0071 | Cost: 0.4018\n",
      "Epoch: 028/075 | Batch 0050/0071 | Cost: 0.4117\n",
      "Epoch: 028/075 | Batch 0060/0071 | Cost: 0.4139\n",
      "Epoch: 028/075 | Batch 0070/0071 | Cost: 0.4071\n",
      "MAE/RMSE: | Current Valid: 7.96/12.01/87.35 Ep. 27 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 16.59 min\n",
      "Epoch: 029/075 | Batch 0000/0071 | Cost: 0.2681\n",
      "Epoch: 029/075 | Batch 0010/0071 | Cost: 0.3674\n",
      "Epoch: 029/075 | Batch 0020/0071 | Cost: 0.3018\n",
      "Epoch: 029/075 | Batch 0030/0071 | Cost: 0.2284\n",
      "Epoch: 029/075 | Batch 0040/0071 | Cost: 0.2812\n",
      "Epoch: 029/075 | Batch 0050/0071 | Cost: 0.3267\n",
      "Epoch: 029/075 | Batch 0060/0071 | Cost: 0.3851\n",
      "Epoch: 029/075 | Batch 0070/0071 | Cost: 0.4910\n",
      "MAE/RMSE: | Current Valid: 7.25/11.31/88.10 Ep. 28 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 17.13 min\n",
      "Epoch: 030/075 | Batch 0000/0071 | Cost: 0.2667\n",
      "Epoch: 030/075 | Batch 0010/0071 | Cost: 0.2929\n",
      "Epoch: 030/075 | Batch 0020/0071 | Cost: 0.3159\n",
      "Epoch: 030/075 | Batch 0030/0071 | Cost: 0.2951\n",
      "Epoch: 030/075 | Batch 0040/0071 | Cost: 0.3601\n",
      "Epoch: 030/075 | Batch 0050/0071 | Cost: 0.3706\n",
      "Epoch: 030/075 | Batch 0060/0071 | Cost: 0.3437\n",
      "Epoch: 030/075 | Batch 0070/0071 | Cost: 0.3715\n",
      "MAE/RMSE: | Current Valid: 7.17/10.84/88.88 Ep. 29 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 17.72 min\n",
      "Epoch: 031/075 | Batch 0000/0071 | Cost: 0.1912\n",
      "Epoch: 031/075 | Batch 0010/0071 | Cost: 0.3078\n",
      "Epoch: 031/075 | Batch 0020/0071 | Cost: 0.2597\n",
      "Epoch: 031/075 | Batch 0030/0071 | Cost: 0.2923\n",
      "Epoch: 031/075 | Batch 0040/0071 | Cost: 0.4203\n",
      "Epoch: 031/075 | Batch 0050/0071 | Cost: 0.3189\n",
      "Epoch: 031/075 | Batch 0060/0071 | Cost: 0.3212\n",
      "Epoch: 031/075 | Batch 0070/0071 | Cost: 0.4114\n",
      "MAE/RMSE: | Current Valid: 7.41/11.31/89.06 Ep. 30 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 18.25 min\n",
      "Epoch: 032/075 | Batch 0000/0071 | Cost: 0.1939\n",
      "Epoch: 032/075 | Batch 0010/0071 | Cost: 0.3092\n",
      "Epoch: 032/075 | Batch 0020/0071 | Cost: 0.2064\n",
      "Epoch: 032/075 | Batch 0030/0071 | Cost: 0.2282\n",
      "Epoch: 032/075 | Batch 0040/0071 | Cost: 0.2494\n",
      "Epoch: 032/075 | Batch 0050/0071 | Cost: 0.2984\n",
      "Epoch: 032/075 | Batch 0060/0071 | Cost: 0.3752\n",
      "Epoch: 032/075 | Batch 0070/0071 | Cost: 0.4758\n",
      "MAE/RMSE: | Current Valid: 7.08/11.06/89.37 Ep. 31 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 18.79 min\n",
      "Epoch: 033/075 | Batch 0000/0071 | Cost: 0.1860\n",
      "Epoch: 033/075 | Batch 0010/0071 | Cost: 0.1918\n",
      "Epoch: 033/075 | Batch 0020/0071 | Cost: 0.3662\n",
      "Epoch: 033/075 | Batch 0030/0071 | Cost: 0.2414\n",
      "Epoch: 033/075 | Batch 0040/0071 | Cost: 0.2549\n",
      "Epoch: 033/075 | Batch 0050/0071 | Cost: 0.2347\n",
      "Epoch: 033/075 | Batch 0060/0071 | Cost: 0.2920\n",
      "Epoch: 033/075 | Batch 0070/0071 | Cost: 0.3520\n",
      "MAE/RMSE: | Current Valid: 7.64/12.29/88.84 Ep. 32 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 19.31 min\n",
      "Epoch: 034/075 | Batch 0000/0071 | Cost: 0.1682\n",
      "Epoch: 034/075 | Batch 0010/0071 | Cost: 0.2467\n",
      "Epoch: 034/075 | Batch 0020/0071 | Cost: 0.3495\n",
      "Epoch: 034/075 | Batch 0030/0071 | Cost: 0.2545\n",
      "Epoch: 034/075 | Batch 0040/0071 | Cost: 0.4292\n",
      "Epoch: 034/075 | Batch 0050/0071 | Cost: 0.1904\n",
      "Epoch: 034/075 | Batch 0060/0071 | Cost: 0.1759\n",
      "Epoch: 034/075 | Batch 0070/0071 | Cost: 0.2206\n",
      "MAE/RMSE: | Current Valid: 7.58/11.54/86.78 Ep. 33 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 19.82 min\n",
      "Epoch: 035/075 | Batch 0000/0071 | Cost: 0.2787\n",
      "Epoch: 035/075 | Batch 0010/0071 | Cost: 0.2354\n",
      "Epoch: 035/075 | Batch 0020/0071 | Cost: 0.1421\n",
      "Epoch: 035/075 | Batch 0030/0071 | Cost: 0.2879\n",
      "Epoch: 035/075 | Batch 0040/0071 | Cost: 0.2667\n",
      "Epoch: 035/075 | Batch 0050/0071 | Cost: 0.2185\n",
      "Epoch: 035/075 | Batch 0060/0071 | Cost: 0.2893\n",
      "Epoch: 035/075 | Batch 0070/0071 | Cost: 0.3086\n",
      "MAE/RMSE: | Current Valid: 7.32/11.43/88.32 Ep. 34 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 20.34 min\n",
      "Epoch: 036/075 | Batch 0000/0071 | Cost: 0.1199\n",
      "Epoch: 036/075 | Batch 0010/0071 | Cost: 0.2039\n",
      "Epoch: 036/075 | Batch 0020/0071 | Cost: 0.2093\n",
      "Epoch: 036/075 | Batch 0030/0071 | Cost: 0.2057\n",
      "Epoch: 036/075 | Batch 0040/0071 | Cost: 0.2683\n",
      "Epoch: 036/075 | Batch 0050/0071 | Cost: 0.2494\n",
      "Epoch: 036/075 | Batch 0060/0071 | Cost: 0.3522\n",
      "Epoch: 036/075 | Batch 0070/0071 | Cost: 0.3393\n",
      "MAE/RMSE: | Current Valid: 8.08/12.22/88.62 Ep. 35 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 20.87 min\n",
      "Epoch: 037/075 | Batch 0000/0071 | Cost: 0.1856\n",
      "Epoch: 037/075 | Batch 0010/0071 | Cost: 0.2058\n",
      "Epoch: 037/075 | Batch 0020/0071 | Cost: 0.2183\n",
      "Epoch: 037/075 | Batch 0030/0071 | Cost: 0.2104\n",
      "Epoch: 037/075 | Batch 0040/0071 | Cost: 0.1724\n",
      "Epoch: 037/075 | Batch 0050/0071 | Cost: 0.2733\n",
      "Epoch: 037/075 | Batch 0060/0071 | Cost: 0.1892\n",
      "Epoch: 037/075 | Batch 0070/0071 | Cost: 0.2323\n",
      "MAE/RMSE: | Current Valid: 7.33/11.38/89.23 Ep. 36 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 21.44 min\n",
      "Epoch: 038/075 | Batch 0000/0071 | Cost: 0.2113\n",
      "Epoch: 038/075 | Batch 0010/0071 | Cost: 0.2165\n",
      "Epoch: 038/075 | Batch 0020/0071 | Cost: 0.1808\n",
      "Epoch: 038/075 | Batch 0030/0071 | Cost: 0.2033\n",
      "Epoch: 038/075 | Batch 0040/0071 | Cost: 0.1854\n",
      "Epoch: 038/075 | Batch 0050/0071 | Cost: 0.1766\n",
      "Epoch: 038/075 | Batch 0060/0071 | Cost: 0.1895\n",
      "Epoch: 038/075 | Batch 0070/0071 | Cost: 0.3513\n",
      "MAE/RMSE: | Current Valid: 7.38/11.24/88.80 Ep. 37 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 21.98 min\n",
      "Epoch: 039/075 | Batch 0000/0071 | Cost: 0.1853\n",
      "Epoch: 039/075 | Batch 0010/0071 | Cost: 0.1364\n",
      "Epoch: 039/075 | Batch 0020/0071 | Cost: 0.2556\n",
      "Epoch: 039/075 | Batch 0030/0071 | Cost: 0.2604\n",
      "Epoch: 039/075 | Batch 0040/0071 | Cost: 0.2086\n",
      "Epoch: 039/075 | Batch 0050/0071 | Cost: 0.3187\n",
      "Epoch: 039/075 | Batch 0060/0071 | Cost: 0.2163\n",
      "Epoch: 039/075 | Batch 0070/0071 | Cost: 0.2373\n",
      "MAE/RMSE: | Current Valid: 7.02/10.65/87.96 Ep. 38 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 22.54 min\n",
      "Epoch: 040/075 | Batch 0000/0071 | Cost: 0.1085\n",
      "Epoch: 040/075 | Batch 0010/0071 | Cost: 0.1556\n",
      "Epoch: 040/075 | Batch 0020/0071 | Cost: 0.1905\n",
      "Epoch: 040/075 | Batch 0030/0071 | Cost: 0.1567\n",
      "Epoch: 040/075 | Batch 0040/0071 | Cost: 0.1841\n",
      "Epoch: 040/075 | Batch 0050/0071 | Cost: 0.1610\n",
      "Epoch: 040/075 | Batch 0060/0071 | Cost: 0.1901\n",
      "Epoch: 040/075 | Batch 0070/0071 | Cost: 0.2443\n",
      "MAE/RMSE: | Current Valid: 11.51/17.41/88.49 Ep. 39 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 23.09 min\n",
      "Epoch: 041/075 | Batch 0000/0071 | Cost: 0.1103\n",
      "Epoch: 041/075 | Batch 0010/0071 | Cost: 0.1144\n",
      "Epoch: 041/075 | Batch 0020/0071 | Cost: 0.2482\n",
      "Epoch: 041/075 | Batch 0030/0071 | Cost: 0.1353\n",
      "Epoch: 041/075 | Batch 0040/0071 | Cost: 0.1601\n",
      "Epoch: 041/075 | Batch 0050/0071 | Cost: 0.2498\n",
      "Epoch: 041/075 | Batch 0060/0071 | Cost: 0.2053\n",
      "Epoch: 041/075 | Batch 0070/0071 | Cost: 0.2319\n",
      "MAE/RMSE: | Current Valid: 16.75/24.79/87.57 Ep. 40 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 23.63 min\n",
      "Epoch: 042/075 | Batch 0000/0071 | Cost: 0.1107\n",
      "Epoch: 042/075 | Batch 0010/0071 | Cost: 0.1994\n",
      "Epoch: 042/075 | Batch 0020/0071 | Cost: 0.1775\n",
      "Epoch: 042/075 | Batch 0030/0071 | Cost: 0.1503\n",
      "Epoch: 042/075 | Batch 0040/0071 | Cost: 0.2240\n",
      "Epoch: 042/075 | Batch 0050/0071 | Cost: 0.1468\n",
      "Epoch: 042/075 | Batch 0060/0071 | Cost: 0.1425\n",
      "Epoch: 042/075 | Batch 0070/0071 | Cost: 0.1981\n",
      "MAE/RMSE: | Current Valid: 7.43/11.48/88.27 Ep. 41 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 24.15 min\n",
      "Epoch: 043/075 | Batch 0000/0071 | Cost: 0.1205\n",
      "Epoch: 043/075 | Batch 0010/0071 | Cost: 0.1534\n",
      "Epoch: 043/075 | Batch 0020/0071 | Cost: 0.2064\n",
      "Epoch: 043/075 | Batch 0030/0071 | Cost: 0.1338\n",
      "Epoch: 043/075 | Batch 0040/0071 | Cost: 0.1522\n",
      "Epoch: 043/075 | Batch 0050/0071 | Cost: 0.1378\n",
      "Epoch: 043/075 | Batch 0060/0071 | Cost: 0.2151\n",
      "Epoch: 043/075 | Batch 0070/0071 | Cost: 0.2091\n",
      "MAE/RMSE: | Current Valid: 15.89/23.36/86.43 Ep. 42 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 24.71 min\n",
      "Epoch: 044/075 | Batch 0000/0071 | Cost: 0.0924\n",
      "Epoch: 044/075 | Batch 0010/0071 | Cost: 0.0969\n",
      "Epoch: 044/075 | Batch 0020/0071 | Cost: 0.1580\n",
      "Epoch: 044/075 | Batch 0030/0071 | Cost: 0.2157\n",
      "Epoch: 044/075 | Batch 0040/0071 | Cost: 0.1724\n",
      "Epoch: 044/075 | Batch 0050/0071 | Cost: 0.2228\n",
      "Epoch: 044/075 | Batch 0060/0071 | Cost: 0.1595\n",
      "Epoch: 044/075 | Batch 0070/0071 | Cost: 0.1944\n",
      "MAE/RMSE: | Current Valid: 7.56/11.38/88.14 Ep. 43 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 25.24 min\n",
      "Epoch: 045/075 | Batch 0000/0071 | Cost: 0.1305\n",
      "Epoch: 045/075 | Batch 0010/0071 | Cost: 0.1918\n",
      "Epoch: 045/075 | Batch 0020/0071 | Cost: 0.1605\n",
      "Epoch: 045/075 | Batch 0030/0071 | Cost: 0.1894\n",
      "Epoch: 045/075 | Batch 0040/0071 | Cost: 0.1825\n",
      "Epoch: 045/075 | Batch 0050/0071 | Cost: 0.2687\n",
      "Epoch: 045/075 | Batch 0060/0071 | Cost: 0.1790\n",
      "Epoch: 045/075 | Batch 0070/0071 | Cost: 0.1811\n",
      "MAE/RMSE: | Current Valid: 7.32/11.24/88.23 Ep. 44 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 25.81 min\n",
      "Epoch: 046/075 | Batch 0000/0071 | Cost: 0.1653\n",
      "Epoch: 046/075 | Batch 0010/0071 | Cost: 0.1629\n",
      "Epoch: 046/075 | Batch 0020/0071 | Cost: 0.1494\n",
      "Epoch: 046/075 | Batch 0030/0071 | Cost: 0.1643\n",
      "Epoch: 046/075 | Batch 0040/0071 | Cost: 0.2832\n",
      "Epoch: 046/075 | Batch 0050/0071 | Cost: 0.1879\n",
      "Epoch: 046/075 | Batch 0060/0071 | Cost: 0.2375\n",
      "Epoch: 046/075 | Batch 0070/0071 | Cost: 0.2536\n",
      "MAE/RMSE: | Current Valid: 12.17/18.49/88.14 Ep. 45 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 26.36 min\n",
      "Epoch: 047/075 | Batch 0000/0071 | Cost: 0.2620\n",
      "Epoch: 047/075 | Batch 0010/0071 | Cost: 0.1050\n",
      "Epoch: 047/075 | Batch 0020/0071 | Cost: 0.2337\n",
      "Epoch: 047/075 | Batch 0030/0071 | Cost: 0.1223\n",
      "Epoch: 047/075 | Batch 0040/0071 | Cost: 0.1435\n",
      "Epoch: 047/075 | Batch 0050/0071 | Cost: 0.1812\n",
      "Epoch: 047/075 | Batch 0060/0071 | Cost: 0.2325\n",
      "Epoch: 047/075 | Batch 0070/0071 | Cost: 0.1846\n",
      "MAE/RMSE: | Current Valid: 7.71/11.57/88.67 Ep. 46 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 26.91 min\n",
      "Epoch: 048/075 | Batch 0000/0071 | Cost: 0.1642\n",
      "Epoch: 048/075 | Batch 0010/0071 | Cost: 0.1955\n",
      "Epoch: 048/075 | Batch 0020/0071 | Cost: 0.2047\n",
      "Epoch: 048/075 | Batch 0030/0071 | Cost: 0.3435\n",
      "Epoch: 048/075 | Batch 0040/0071 | Cost: 0.2825\n",
      "Epoch: 048/075 | Batch 0050/0071 | Cost: 0.1590\n",
      "Epoch: 048/075 | Batch 0060/0071 | Cost: 0.2842\n",
      "Epoch: 048/075 | Batch 0070/0071 | Cost: 0.2439\n",
      "MAE/RMSE: | Current Valid: 7.76/11.88/89.10 Ep. 47 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 27.44 min\n",
      "Epoch: 049/075 | Batch 0000/0071 | Cost: 0.1755\n",
      "Epoch: 049/075 | Batch 0010/0071 | Cost: 0.2741\n",
      "Epoch: 049/075 | Batch 0020/0071 | Cost: 0.2128\n",
      "Epoch: 049/075 | Batch 0030/0071 | Cost: 0.2173\n",
      "Epoch: 049/075 | Batch 0040/0071 | Cost: 0.1844\n",
      "Epoch: 049/075 | Batch 0050/0071 | Cost: 0.2221\n",
      "Epoch: 049/075 | Batch 0060/0071 | Cost: 0.1968\n",
      "Epoch: 049/075 | Batch 0070/0071 | Cost: 0.1816\n",
      "MAE/RMSE: | Current Valid: 8.23/13.15/88.10 Ep. 48 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 27.98 min\n",
      "Epoch: 050/075 | Batch 0000/0071 | Cost: 0.1552\n",
      "Epoch: 050/075 | Batch 0010/0071 | Cost: 0.1591\n",
      "Epoch: 050/075 | Batch 0020/0071 | Cost: 0.1852\n",
      "Epoch: 050/075 | Batch 0030/0071 | Cost: 0.1823\n",
      "Epoch: 050/075 | Batch 0040/0071 | Cost: 0.2405\n",
      "Epoch: 050/075 | Batch 0050/0071 | Cost: 0.2018\n",
      "Epoch: 050/075 | Batch 0060/0071 | Cost: 0.2381\n",
      "Epoch: 050/075 | Batch 0070/0071 | Cost: 0.1521\n",
      "MAE/RMSE: | Current Valid: 7.45/11.27/87.09 Ep. 49 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 28.50 min\n",
      "Epoch: 051/075 | Batch 0000/0071 | Cost: 0.0895\n",
      "Epoch: 051/075 | Batch 0010/0071 | Cost: 0.2213\n",
      "Epoch: 051/075 | Batch 0020/0071 | Cost: 0.1281\n",
      "Epoch: 051/075 | Batch 0030/0071 | Cost: 0.1621\n",
      "Epoch: 051/075 | Batch 0040/0071 | Cost: 0.1457\n",
      "Epoch: 051/075 | Batch 0050/0071 | Cost: 0.1212\n",
      "Epoch: 051/075 | Batch 0060/0071 | Cost: 0.1961\n",
      "Epoch: 051/075 | Batch 0070/0071 | Cost: 0.1820\n",
      "MAE/RMSE: | Current Valid: 8.28/12.87/88.71 Ep. 50 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 29.01 min\n",
      "Epoch: 052/075 | Batch 0000/0071 | Cost: 0.1410\n",
      "Epoch: 052/075 | Batch 0010/0071 | Cost: 0.1297\n",
      "Epoch: 052/075 | Batch 0020/0071 | Cost: 0.1683\n",
      "Epoch: 052/075 | Batch 0030/0071 | Cost: 0.1350\n",
      "Epoch: 052/075 | Batch 0040/0071 | Cost: 0.2037\n",
      "Epoch: 052/075 | Batch 0050/0071 | Cost: 0.1494\n",
      "Epoch: 052/075 | Batch 0060/0071 | Cost: 0.2977\n",
      "Epoch: 052/075 | Batch 0070/0071 | Cost: 0.1659\n",
      "MAE/RMSE: | Current Valid: 10.31/15.71/88.32 Ep. 51 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 29.53 min\n",
      "Epoch: 053/075 | Batch 0000/0071 | Cost: 0.1597\n",
      "Epoch: 053/075 | Batch 0010/0071 | Cost: 0.1189\n",
      "Epoch: 053/075 | Batch 0020/0071 | Cost: 0.1263\n",
      "Epoch: 053/075 | Batch 0030/0071 | Cost: 0.1491\n",
      "Epoch: 053/075 | Batch 0040/0071 | Cost: 0.2014\n",
      "Epoch: 053/075 | Batch 0050/0071 | Cost: 0.1182\n",
      "Epoch: 053/075 | Batch 0060/0071 | Cost: 0.1846\n",
      "Epoch: 053/075 | Batch 0070/0071 | Cost: 0.2019\n",
      "MAE/RMSE: | Current Valid: 7.51/11.12/88.84 Ep. 52 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 30.05 min\n",
      "Epoch: 054/075 | Batch 0000/0071 | Cost: 0.1327\n",
      "Epoch: 054/075 | Batch 0010/0071 | Cost: 0.1652\n",
      "Epoch: 054/075 | Batch 0020/0071 | Cost: 0.1886\n",
      "Epoch: 054/075 | Batch 0030/0071 | Cost: 0.1617\n",
      "Epoch: 054/075 | Batch 0040/0071 | Cost: 0.1493\n",
      "Epoch: 054/075 | Batch 0050/0071 | Cost: 0.1729\n",
      "Epoch: 054/075 | Batch 0060/0071 | Cost: 0.1920\n",
      "Epoch: 054/075 | Batch 0070/0071 | Cost: 0.2505\n",
      "MAE/RMSE: | Current Valid: 8.36/12.45/87.92 Ep. 53 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 30.56 min\n",
      "Epoch: 055/075 | Batch 0000/0071 | Cost: 0.0832\n",
      "Epoch: 055/075 | Batch 0010/0071 | Cost: 0.1608\n",
      "Epoch: 055/075 | Batch 0020/0071 | Cost: 0.1398\n",
      "Epoch: 055/075 | Batch 0030/0071 | Cost: 0.0828\n",
      "Epoch: 055/075 | Batch 0040/0071 | Cost: 0.1972\n",
      "Epoch: 055/075 | Batch 0050/0071 | Cost: 0.0869\n",
      "Epoch: 055/075 | Batch 0060/0071 | Cost: 0.1962\n",
      "Epoch: 055/075 | Batch 0070/0071 | Cost: 0.2182\n",
      "MAE/RMSE: | Current Valid: 7.44/11.48/88.58 Ep. 54 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 31.08 min\n",
      "Epoch: 056/075 | Batch 0000/0071 | Cost: 0.1054\n",
      "Epoch: 056/075 | Batch 0010/0071 | Cost: 0.1165\n",
      "Epoch: 056/075 | Batch 0020/0071 | Cost: 0.1755\n",
      "Epoch: 056/075 | Batch 0030/0071 | Cost: 0.1777\n",
      "Epoch: 056/075 | Batch 0040/0071 | Cost: 0.1158\n",
      "Epoch: 056/075 | Batch 0050/0071 | Cost: 0.1503\n",
      "Epoch: 056/075 | Batch 0060/0071 | Cost: 0.2336\n",
      "Epoch: 056/075 | Batch 0070/0071 | Cost: 0.2329\n",
      "MAE/RMSE: | Current Valid: 7.92/12.04/87.96 Ep. 55 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 31.60 min\n",
      "Epoch: 057/075 | Batch 0000/0071 | Cost: 0.1475\n",
      "Epoch: 057/075 | Batch 0010/0071 | Cost: 0.1494\n",
      "Epoch: 057/075 | Batch 0020/0071 | Cost: 0.1459\n",
      "Epoch: 057/075 | Batch 0030/0071 | Cost: 0.1479\n",
      "Epoch: 057/075 | Batch 0040/0071 | Cost: 0.1684\n",
      "Epoch: 057/075 | Batch 0050/0071 | Cost: 0.1152\n",
      "Epoch: 057/075 | Batch 0060/0071 | Cost: 0.1558\n",
      "Epoch: 057/075 | Batch 0070/0071 | Cost: 0.1824\n",
      "MAE/RMSE: | Current Valid: 7.39/11.32/88.97 Ep. 56 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 32.12 min\n",
      "Epoch: 058/075 | Batch 0000/0071 | Cost: 0.1343\n",
      "Epoch: 058/075 | Batch 0010/0071 | Cost: 0.1741\n",
      "Epoch: 058/075 | Batch 0020/0071 | Cost: 0.1667\n",
      "Epoch: 058/075 | Batch 0030/0071 | Cost: 0.1021\n",
      "Epoch: 058/075 | Batch 0040/0071 | Cost: 0.1384\n",
      "Epoch: 058/075 | Batch 0050/0071 | Cost: 0.1761\n",
      "Epoch: 058/075 | Batch 0060/0071 | Cost: 0.2523\n",
      "Epoch: 058/075 | Batch 0070/0071 | Cost: 0.2131\n",
      "MAE/RMSE: | Current Valid: 12.65/18.60/88.45 Ep. 57 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 32.64 min\n",
      "Epoch: 059/075 | Batch 0000/0071 | Cost: 0.1298\n",
      "Epoch: 059/075 | Batch 0010/0071 | Cost: 0.0581\n",
      "Epoch: 059/075 | Batch 0020/0071 | Cost: 0.1594\n",
      "Epoch: 059/075 | Batch 0030/0071 | Cost: 0.2280\n",
      "Epoch: 059/075 | Batch 0040/0071 | Cost: 0.2063\n",
      "Epoch: 059/075 | Batch 0050/0071 | Cost: 0.2467\n",
      "Epoch: 059/075 | Batch 0060/0071 | Cost: 0.2520\n",
      "Epoch: 059/075 | Batch 0070/0071 | Cost: 0.1542\n",
      "MAE/RMSE: | Current Valid: 11.44/17.42/87.40 Ep. 58 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 33.16 min\n",
      "Epoch: 060/075 | Batch 0000/0071 | Cost: 0.1811\n",
      "Epoch: 060/075 | Batch 0010/0071 | Cost: 0.1656\n",
      "Epoch: 060/075 | Batch 0020/0071 | Cost: 0.1885\n",
      "Epoch: 060/075 | Batch 0030/0071 | Cost: 0.0896\n",
      "Epoch: 060/075 | Batch 0040/0071 | Cost: 0.1675\n",
      "Epoch: 060/075 | Batch 0050/0071 | Cost: 0.1979\n",
      "Epoch: 060/075 | Batch 0060/0071 | Cost: 0.1223\n",
      "Epoch: 060/075 | Batch 0070/0071 | Cost: 0.1840\n",
      "MAE/RMSE: | Current Valid: 8.12/12.83/88.05 Ep. 59 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 33.68 min\n",
      "Epoch: 061/075 | Batch 0000/0071 | Cost: 0.1242\n",
      "Epoch: 061/075 | Batch 0010/0071 | Cost: 0.2294\n",
      "Epoch: 061/075 | Batch 0020/0071 | Cost: 0.1861\n",
      "Epoch: 061/075 | Batch 0030/0071 | Cost: 0.2072\n",
      "Epoch: 061/075 | Batch 0040/0071 | Cost: 0.2504\n",
      "Epoch: 061/075 | Batch 0050/0071 | Cost: 0.1423\n",
      "Epoch: 061/075 | Batch 0060/0071 | Cost: 0.2017\n",
      "Epoch: 061/075 | Batch 0070/0071 | Cost: 0.1436\n",
      "MAE/RMSE: | Current Valid: 7.29/11.32/88.36 Ep. 60 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 34.19 min\n",
      "Epoch: 062/075 | Batch 0000/0071 | Cost: 0.1954\n",
      "Epoch: 062/075 | Batch 0010/0071 | Cost: 0.2445\n",
      "Epoch: 062/075 | Batch 0020/0071 | Cost: 0.1919\n",
      "Epoch: 062/075 | Batch 0030/0071 | Cost: 0.2206\n",
      "Epoch: 062/075 | Batch 0040/0071 | Cost: 0.2205\n",
      "Epoch: 062/075 | Batch 0050/0071 | Cost: 0.2060\n",
      "Epoch: 062/075 | Batch 0060/0071 | Cost: 0.1372\n",
      "Epoch: 062/075 | Batch 0070/0071 | Cost: 0.2045\n",
      "MAE/RMSE: | Current Valid: 9.99/15.28/87.66 Ep. 61 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 34.69 min\n",
      "Epoch: 063/075 | Batch 0000/0071 | Cost: 0.1188\n",
      "Epoch: 063/075 | Batch 0010/0071 | Cost: 0.2342\n",
      "Epoch: 063/075 | Batch 0020/0071 | Cost: 0.1786\n",
      "Epoch: 063/075 | Batch 0030/0071 | Cost: 0.1697\n",
      "Epoch: 063/075 | Batch 0040/0071 | Cost: 0.1338\n",
      "Epoch: 063/075 | Batch 0050/0071 | Cost: 0.1539\n",
      "Epoch: 063/075 | Batch 0060/0071 | Cost: 0.1885\n",
      "Epoch: 063/075 | Batch 0070/0071 | Cost: 0.1662\n",
      "MAE/RMSE: | Current Valid: 7.22/11.09/88.67 Ep. 62 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 35.21 min\n",
      "Epoch: 064/075 | Batch 0000/0071 | Cost: 0.1478\n",
      "Epoch: 064/075 | Batch 0010/0071 | Cost: 0.1182\n",
      "Epoch: 064/075 | Batch 0020/0071 | Cost: 0.0864\n",
      "Epoch: 064/075 | Batch 0030/0071 | Cost: 0.1552\n",
      "Epoch: 064/075 | Batch 0040/0071 | Cost: 0.1936\n",
      "Epoch: 064/075 | Batch 0050/0071 | Cost: 0.1325\n",
      "Epoch: 064/075 | Batch 0060/0071 | Cost: 0.1343\n",
      "Epoch: 064/075 | Batch 0070/0071 | Cost: 0.1628\n",
      "MAE/RMSE: | Current Valid: 9.71/15.12/88.75 Ep. 63 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 35.76 min\n",
      "Epoch: 065/075 | Batch 0000/0071 | Cost: 0.0867\n",
      "Epoch: 065/075 | Batch 0010/0071 | Cost: 0.1776\n",
      "Epoch: 065/075 | Batch 0020/0071 | Cost: 0.0628\n",
      "Epoch: 065/075 | Batch 0030/0071 | Cost: 0.1146\n",
      "Epoch: 065/075 | Batch 0040/0071 | Cost: 0.0870\n",
      "Epoch: 065/075 | Batch 0050/0071 | Cost: 0.1241\n",
      "Epoch: 065/075 | Batch 0060/0071 | Cost: 0.1073\n",
      "Epoch: 065/075 | Batch 0070/0071 | Cost: 0.1147\n",
      "MAE/RMSE: | Current Valid: 7.34/11.40/88.23 Ep. 64 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 36.31 min\n",
      "Epoch: 066/075 | Batch 0000/0071 | Cost: 0.0605\n",
      "Epoch: 066/075 | Batch 0010/0071 | Cost: 0.1537\n",
      "Epoch: 066/075 | Batch 0020/0071 | Cost: 0.1440\n",
      "Epoch: 066/075 | Batch 0030/0071 | Cost: 0.1068\n",
      "Epoch: 066/075 | Batch 0040/0071 | Cost: 0.1358\n",
      "Epoch: 066/075 | Batch 0050/0071 | Cost: 0.1463\n",
      "Epoch: 066/075 | Batch 0060/0071 | Cost: 0.0729\n",
      "Epoch: 066/075 | Batch 0070/0071 | Cost: 0.0808\n",
      "MAE/RMSE: | Current Valid: 7.43/11.29/88.80 Ep. 65 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 36.86 min\n",
      "Epoch: 067/075 | Batch 0000/0071 | Cost: 0.0611\n",
      "Epoch: 067/075 | Batch 0010/0071 | Cost: 0.1169\n",
      "Epoch: 067/075 | Batch 0020/0071 | Cost: 0.1082\n",
      "Epoch: 067/075 | Batch 0030/0071 | Cost: 0.1376\n",
      "Epoch: 067/075 | Batch 0040/0071 | Cost: 0.1616\n",
      "Epoch: 067/075 | Batch 0050/0071 | Cost: 0.1468\n",
      "Epoch: 067/075 | Batch 0060/0071 | Cost: 0.1056\n",
      "Epoch: 067/075 | Batch 0070/0071 | Cost: 0.1929\n",
      "MAE/RMSE: | Current Valid: 11.16/17.32/87.92 Ep. 66 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 37.38 min\n",
      "Epoch: 068/075 | Batch 0000/0071 | Cost: 0.1312\n",
      "Epoch: 068/075 | Batch 0010/0071 | Cost: 0.1517\n",
      "Epoch: 068/075 | Batch 0020/0071 | Cost: 0.0834\n",
      "Epoch: 068/075 | Batch 0030/0071 | Cost: 0.1420\n",
      "Epoch: 068/075 | Batch 0040/0071 | Cost: 0.1672\n",
      "Epoch: 068/075 | Batch 0050/0071 | Cost: 0.1580\n",
      "Epoch: 068/075 | Batch 0060/0071 | Cost: 0.0967\n",
      "Epoch: 068/075 | Batch 0070/0071 | Cost: 0.0932\n",
      "MAE/RMSE: | Current Valid: 8.96/14.11/88.18 Ep. 67 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 37.90 min\n",
      "Epoch: 069/075 | Batch 0000/0071 | Cost: 0.0885\n",
      "Epoch: 069/075 | Batch 0010/0071 | Cost: 0.1268\n",
      "Epoch: 069/075 | Batch 0020/0071 | Cost: 0.0636\n",
      "Epoch: 069/075 | Batch 0030/0071 | Cost: 0.1239\n",
      "Epoch: 069/075 | Batch 0040/0071 | Cost: 0.1292\n",
      "Epoch: 069/075 | Batch 0050/0071 | Cost: 0.1096\n",
      "Epoch: 069/075 | Batch 0060/0071 | Cost: 0.1009\n",
      "Epoch: 069/075 | Batch 0070/0071 | Cost: 0.0984\n",
      "MAE/RMSE: | Current Valid: 7.56/11.32/88.53 Ep. 68 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 38.40 min\n",
      "Epoch: 070/075 | Batch 0000/0071 | Cost: 0.0967\n",
      "Epoch: 070/075 | Batch 0010/0071 | Cost: 0.1331\n",
      "Epoch: 070/075 | Batch 0020/0071 | Cost: 0.1429\n",
      "Epoch: 070/075 | Batch 0030/0071 | Cost: 0.0577\n",
      "Epoch: 070/075 | Batch 0040/0071 | Cost: 0.1907\n",
      "Epoch: 070/075 | Batch 0050/0071 | Cost: 0.1483\n",
      "Epoch: 070/075 | Batch 0060/0071 | Cost: 0.1218\n",
      "Epoch: 070/075 | Batch 0070/0071 | Cost: 0.1376\n",
      "MAE/RMSE: | Current Valid: 7.19/11.09/88.84 Ep. 69 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 38.93 min\n",
      "Epoch: 071/075 | Batch 0000/0071 | Cost: 0.1460\n",
      "Epoch: 071/075 | Batch 0010/0071 | Cost: 0.1475\n",
      "Epoch: 071/075 | Batch 0020/0071 | Cost: 0.0720\n",
      "Epoch: 071/075 | Batch 0030/0071 | Cost: 0.0765\n",
      "Epoch: 071/075 | Batch 0040/0071 | Cost: 0.1290\n",
      "Epoch: 071/075 | Batch 0050/0071 | Cost: 0.0974\n",
      "Epoch: 071/075 | Batch 0060/0071 | Cost: 0.1612\n",
      "Epoch: 071/075 | Batch 0070/0071 | Cost: 0.1462\n",
      "MAE/RMSE: | Current Valid: 8.03/12.79/88.18 Ep. 70 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 39.44 min\n",
      "Epoch: 072/075 | Batch 0000/0071 | Cost: 0.0983\n",
      "Epoch: 072/075 | Batch 0010/0071 | Cost: 0.1138\n",
      "Epoch: 072/075 | Batch 0020/0071 | Cost: 0.0660\n",
      "Epoch: 072/075 | Batch 0030/0071 | Cost: 0.2071\n",
      "Epoch: 072/075 | Batch 0040/0071 | Cost: 0.1410\n",
      "Epoch: 072/075 | Batch 0050/0071 | Cost: 0.1458\n",
      "Epoch: 072/075 | Batch 0060/0071 | Cost: 0.2032\n",
      "Epoch: 072/075 | Batch 0070/0071 | Cost: 0.1620\n",
      "MAE/RMSE: | Current Valid: 7.64/11.67/88.05 Ep. 71 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 39.97 min\n",
      "Epoch: 073/075 | Batch 0000/0071 | Cost: 0.1030\n",
      "Epoch: 073/075 | Batch 0010/0071 | Cost: 0.1738\n",
      "Epoch: 073/075 | Batch 0020/0071 | Cost: 0.1024\n",
      "Epoch: 073/075 | Batch 0030/0071 | Cost: 0.1868\n",
      "Epoch: 073/075 | Batch 0040/0071 | Cost: 0.1568\n",
      "Epoch: 073/075 | Batch 0050/0071 | Cost: 0.1597\n",
      "Epoch: 073/075 | Batch 0060/0071 | Cost: 0.1036\n",
      "Epoch: 073/075 | Batch 0070/0071 | Cost: 0.1173\n",
      "MAE/RMSE: | Current Valid: 7.28/11.17/89.02 Ep. 72 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 40.51 min\n",
      "Epoch: 074/075 | Batch 0000/0071 | Cost: 0.1305\n",
      "Epoch: 074/075 | Batch 0010/0071 | Cost: 0.1738\n",
      "Epoch: 074/075 | Batch 0020/0071 | Cost: 0.1653\n",
      "Epoch: 074/075 | Batch 0030/0071 | Cost: 0.1416\n",
      "Epoch: 074/075 | Batch 0040/0071 | Cost: 0.2088\n",
      "Epoch: 074/075 | Batch 0050/0071 | Cost: 0.1328\n",
      "Epoch: 074/075 | Batch 0060/0071 | Cost: 0.1472\n",
      "Epoch: 074/075 | Batch 0070/0071 | Cost: 0.2014\n",
      "MAE/RMSE: | Current Valid: 9.18/13.91/88.49 Ep. 73 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 41.04 min\n",
      "Epoch: 075/075 | Batch 0000/0071 | Cost: 0.0879\n",
      "Epoch: 075/075 | Batch 0010/0071 | Cost: 0.2018\n",
      "Epoch: 075/075 | Batch 0020/0071 | Cost: 0.1000\n",
      "Epoch: 075/075 | Batch 0030/0071 | Cost: 0.1852\n",
      "Epoch: 075/075 | Batch 0040/0071 | Cost: 0.1869\n",
      "Epoch: 075/075 | Batch 0050/0071 | Cost: 0.1127\n",
      "Epoch: 075/075 | Batch 0060/0071 | Cost: 0.1589\n",
      "Epoch: 075/075 | Batch 0070/0071 | Cost: 0.1866\n",
      "MAE/RMSE: | Current Valid: 7.52/11.45/88.10 Ep. 74 | Best Valid : 6.73/9.76/85.82 Ep. 11\n",
      "Time elapsed: 41.57 min\n",
      "MAE/RMSE: | Train: 0.44/2.74/98.92 | Valid: 7.52/11.45/88.10 | Test: 7.44/11.17/88.54\n",
      "Total Training Time: 42.09 min\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "model = resnet34(num_classes=117,grayscale=GRAYSCALE)\n",
    "model.to(DEVICE)\n",
    "# ADAM Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "\n",
    "\n",
    "def compute_mae_and_mse(model, data_loader, device):\n",
    "    mae, mse, num_examples1, num_examples2, correct_pred= 0, 0, 0, 0, 0\n",
    "    for i, (features, target1, target2) in enumerate(data_loader):\n",
    "\n",
    "        features = features.to(device)\n",
    "        target1 = target1.to(device)\n",
    "        target2 = target2.float().to(device)\n",
    "        logits1, logits2, probas1, probas2 = model(features)\n",
    "        \n",
    "        _,predicted_labels1 = torch.max(probas1,dim=1)\n",
    "        predicted_labels2 = torch.argmax(probas2,dim=1)\n",
    "        num_examples1 += target1.size(0)\n",
    "        num_examples2 += target2.size(0)\n",
    "        \n",
    "        mae += torch.sum(torch.abs(predicted_labels1- target1))\n",
    "        mse += torch.sum((predicted_labels1- target1)**2)\n",
    "        correct_pred += (predicted_labels2==target2).sum()\n",
    "        \n",
    "    gender_acc = (correct_pred.float()/num_examples2)*100\n",
    "    mae = mae.float() / num_examples1\n",
    "    mse = mse.float() / num_examples1\n",
    "    return mae, mse, gender_acc\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "best_mae, best_rmse, best_epoch = 999, 999, -1\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (features, target1, target2) in enumerate(train_loader):\n",
    "        features = features.to(DEVICE)\n",
    "        target1= target1.to(DEVICE)\n",
    "        target2 = target2.to(DEVICE)\n",
    "\n",
    "        # Forward and Back Propagation\n",
    "        logits1, logits2, probas1, probas2=model(features)\n",
    "        # Cross Entropy Loss Function for Multi-Class Classification(Age)\n",
    "        demo1=nn.CrossEntropyLoss()\n",
    "        cost1 = demo1(logits1,target1)\n",
    "        # Cross Entropy Loss Function Gender Classification\n",
    "        demo2= nn.CrossEntropyLoss()\n",
    "        cost2 = demo2(logits2,target2)\n",
    "        # Cumulative Cost of Age and Gender\n",
    "        cost=cost1+cost2\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cost.backward()\n",
    "\n",
    "        # Updating the Parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Writing to Logfile\n",
    "        if not batch_idx % 10:\n",
    "            s = ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f'\n",
    "                 % (epoch+1, num_epochs, batch_idx,\n",
    "                     len(train_dataset)//BATCH_SIZE, cost))\n",
    "            print(s)\n",
    "            with open(LOGFILE, 'a') as f:\n",
    "                f.write('%s\\n' % s)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        valid_mae, valid_mse, valid_gender = compute_mae_and_mse(model, valid_loader,\n",
    "                                                   device=DEVICE)\n",
    "\n",
    "    if valid_mae < best_mae:\n",
    "        best_mae, best_rmse, best_gacc, best_epoch = valid_mae, torch.sqrt(valid_mse),valid_gender, epoch\n",
    "        torch.save(model.state_dict(), os.path.join(Path, 'Age_and_Gender.pt'))\n",
    "\n",
    "\n",
    "    s = 'MAE/RMSE: | Current Valid: %.2f/%.2f/%.2f Ep. %d | Best Valid : %.2f/%.2f/%.2f Ep. %d' % (\n",
    "        valid_mae, torch.sqrt(valid_mse), valid_gender, epoch, best_mae, best_rmse, best_gacc, best_epoch)\n",
    "    print(s)\n",
    "    with open(LOGFILE, 'a') as f:\n",
    "        f.write('%s\\n' % s)\n",
    "\n",
    "    s = 'Time elapsed: %.2f min' % ((time.time() - start_time)/60)\n",
    "    print(s)\n",
    "    with open(LOGFILE, 'a') as f:\n",
    "        f.write('%s\\n' % s)\n",
    "\n",
    "model.eval()\n",
    "with torch.set_grad_enabled(False):  # save memory during inference\n",
    "\n",
    "    train_mae, train_mse, train_gender = compute_mae_and_mse(model, train_loader,\n",
    "                                               device=DEVICE)\n",
    "    valid_mae, valid_mse, valid_gender = compute_mae_and_mse(model, valid_loader,\n",
    "                                               device=DEVICE)\n",
    "    test_mae, test_mse, test_gender= compute_mae_and_mse(model, test_loader,\n",
    "                                             device=DEVICE)\n",
    "\n",
    "    s = 'MAE/RMSE: | Train: %.2f/%.2f/%.2f | Valid: %.2f/%.2f/%.2f | Test: %.2f/%.2f/%.2f' % (\n",
    "        train_mae, torch.sqrt(train_mse),train_gender,\n",
    "        valid_mae, torch.sqrt(valid_mse),valid_gender,\n",
    "        test_mae, torch.sqrt(test_mse),test_gender)\n",
    "    print(s)\n",
    "    with open(LOGFILE, 'a') as f:\n",
    "        f.write('%s\\n' % s)\n",
    "\n",
    "s = 'Total Training Time: %.2f min' % ((time.time() - start_time)/60)\n",
    "print(s)\n",
    "with open(LOGFILE, 'a') as f:\n",
    "    f.write('%s\\n' % s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a73bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T09:35:41.308085Z",
     "iopub.status.busy": "2023-08-08T09:35:41.306969Z",
     "iopub.status.idle": "2023-08-08T09:36:13.462307Z",
     "shell.execute_reply": "2023-08-08T09:36:13.460919Z"
    },
    "papermill": {
     "duration": 32.211892,
     "end_time": "2023-08-08T09:36:13.465249",
     "exception": false,
     "start_time": "2023-08-08T09:35:41.253357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE/RMSE: | Best Train: 5.37/8.56/87.52 | Best Valid: 6.73/9.76/85.82 | Best Test: 7.13/10.79/83.78\n"
     ]
    }
   ],
   "source": [
    "# Save Best Model\n",
    "model.load_state_dict(torch.load(os.path.join(Path, 'Age_and_Gender.pt')))\n",
    "model.eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_mae, train_mse, train_gender = compute_mae_and_mse(model, train_loader,\n",
    "                                               device=DEVICE)\n",
    "    valid_mae, valid_mse ,valid_gender= compute_mae_and_mse(model, valid_loader,\n",
    "                                               device=DEVICE)\n",
    "    test_mae, test_mse, test_gender = compute_mae_and_mse(model, test_loader,\n",
    "                                             device=DEVICE)\n",
    "\n",
    "    s = 'MAE/RMSE: | Best Train: %.2f/%.2f/%.2f | Best Valid: %.2f/%.2f/%.2f | Best Test: %.2f/%.2f/%.2f' % (\n",
    "        train_mae, torch.sqrt(train_mse),train_gender,\n",
    "        valid_mae, torch.sqrt(valid_mse),valid_gender,\n",
    "        test_mae, torch.sqrt(test_mse), test_gender)\n",
    "    print(s)\n",
    "    with open(LOGFILE, 'a') as f:\n",
    "        f.write('%s\\n' % s)\n",
    "\n",
    "\n",
    "# Writing Predictions into Logfiles\n",
    "all_pred1 = []\n",
    "all_pred2 = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch_idx, (features, target1, target2) in enumerate(test_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        logits1,logits2,probas1,probas2 = model(features)\n",
    "        predict_levels = probas1 > 0.5\n",
    "        predictions = probas2 > 0.5\n",
    "        predicted_labels1 = torch.sum(predict_levels, dim=1)\n",
    "        predicted_labels2 = torch.sum(predictions, dim=1)\n",
    "        lst1 = [str(int(i)) for i in predicted_labels1]\n",
    "        lst2 = [str(int(j)) for j in predicted_labels2]\n",
    "        all_pred1.extend(lst1)\n",
    "        all_pred2.extend(lst2)\n",
    "\n",
    "with open(TEST_PREDICTIONS1, 'w') as f:\n",
    "    all_pred1 = ','.join(all_pred1)\n",
    "    f.write(all_pred1)\n",
    "with open(TEST_PREDICTIONS2, 'w') as f:\n",
    "    all_pred2 = ','.join(all_pred2)\n",
    "    f.write(all_pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2577.73923,
   "end_time": "2023-08-08T09:36:16.378277",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-08T08:53:18.639047",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
