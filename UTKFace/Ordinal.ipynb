{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3f579f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T07:54:36.408620Z",
     "iopub.status.busy": "2023-08-08T07:54:36.407498Z",
     "iopub.status.idle": "2023-08-08T07:54:38.945735Z",
     "shell.execute_reply": "2023-08-08T07:54:38.944494Z"
    },
    "papermill": {
     "duration": 2.547343,
     "end_time": "2023-08-08T07:54:38.948890",
     "exception": false,
     "start_time": "2023-08-08T07:54:36.401547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import sys\n",
    "import torchvision.models as models\n",
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86485134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T07:54:38.957487Z",
     "iopub.status.busy": "2023-08-08T07:54:38.957033Z",
     "iopub.status.idle": "2023-08-08T07:54:39.033078Z",
     "shell.execute_reply": "2023-08-08T07:54:39.031948Z"
    },
    "papermill": {
     "duration": 0.083351,
     "end_time": "2023-08-08T07:54:39.035844",
     "exception": false,
     "start_time": "2023-08-08T07:54:38.952493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.13.0\n",
      "CUDA device available: True\n",
      "Using CUDA device: cuda:0\n",
      "Random Seed: 0\n",
      "Task Importance Weight: 0\n",
      "Output Path: ./OR-CNN\n",
      "Script: /opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\n"
     ]
    }
   ],
   "source": [
    "TRAIN_CSV_PATH = \"/kaggle/input/utkface/Dataset/Index/Train.csv\"\n",
    "VALID_CSV_PATH = \"/kaggle/input/utkface/Dataset/Index/Validation.csv\"\n",
    "TEST_CSV_PATH = \"/kaggle/input/utkface/Dataset/Index/Test.csv\"\n",
    "IMAGE_PATH = \"/kaggle/input/utkface/Dataset/Images\"\n",
    "# Argparse helper\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--cuda',\n",
    "                    type=int,\n",
    "                    default=0)\n",
    "\n",
    "parser.add_argument('--seed',\n",
    "                    type=int,\n",
    "                    default=0)\n",
    "\n",
    "parser.add_argument('--numworkers',\n",
    "                    type=int,\n",
    "                    default=2)\n",
    "\n",
    "\n",
    "parser.add_argument('--outpath',\n",
    "                    type=str,\n",
    "                    required=False,\n",
    "                    default='./OR-CNN')\n",
    "\n",
    "parser.add_argument('--imp_weight',\n",
    "                    type=int,\n",
    "                    default=0)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "NUM_WORKERS = args.numworkers\n",
    "\n",
    "if args.cuda >= 0:\n",
    "    DEVICE = torch.device(\"cuda:%d\" % args.cuda)\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "if args.seed == -1:\n",
    "    RANDOM_SEED = None\n",
    "else:\n",
    "    RANDOM_SEED = args.seed\n",
    "\n",
    "IMP_WEIGHT = args.imp_weight\n",
    "\n",
    "Path = args.outpath\n",
    "#print(Path)\n",
    "if not os.path.exists(Path):\n",
    "  os.mkdir(Path)\n",
    "LOGFILE = os.path.join(Path, 'Training.log')\n",
    "TEST_PREDICTIONS1 = os.path.join(Path, 'Age.log')\n",
    "TEST_PREDICTIONS2 = os.path.join(Path, 'Gender.log')\n",
    "TEST_ALLPROBAS = os.path.join(Path, 'Test_allprobas.tensor')\n",
    "\n",
    "# Logging\n",
    "\n",
    "header = []\n",
    "\n",
    "header.append('PyTorch Version: %s' % torch.__version__)\n",
    "header.append('CUDA device available: %s' % torch.cuda.is_available())\n",
    "header.append('Using CUDA device: %s' % DEVICE)\n",
    "header.append('Random Seed: %s' % RANDOM_SEED)\n",
    "header.append('Task Importance Weight: %s' % IMP_WEIGHT)\n",
    "header.append('Output Path: %s' % Path)\n",
    "header.append('Script: %s' % sys.argv[0])\n",
    "\n",
    "with open(LOGFILE, 'w') as f:\n",
    "    for entry in header:\n",
    "        print(entry)\n",
    "        f.write('%s\\n' % entry)\n",
    "        f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de461088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T07:54:39.044425Z",
     "iopub.status.busy": "2023-08-08T07:54:39.043549Z",
     "iopub.status.idle": "2023-08-08T07:54:41.778176Z",
     "shell.execute_reply": "2023-08-08T07:54:41.777013Z"
    },
    "papermill": {
     "duration": 2.742021,
     "end_time": "2023-08-08T07:54:41.781258",
     "exception": false,
     "start_time": "2023-08-08T07:54:39.039237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "# SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 75\n",
    "\n",
    "# Architecture\n",
    "BATCH_SIZE = 256\n",
    "GRAYSCALE = False\n",
    "\n",
    "df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "ages = df['age'].values\n",
    "gender = df['gender'].values\n",
    "del df\n",
    "ages = torch.tensor(ages, dtype=torch.float)\n",
    "gender = torch.tensor(gender, dtype=torch.float)\n",
    "\n",
    "def task_importance_weights(label_array):\n",
    "    uniq = torch.unique(label_array)\n",
    "    num_examples = label_array.size(0)\n",
    "\n",
    "    m = torch.zeros(uniq.shape[0])\n",
    "\n",
    "    for i, t in enumerate(torch.arange(torch.min(uniq), torch.max(uniq))):\n",
    "        m_k = torch.max(torch.tensor([label_array[label_array > t].size(0), \n",
    "                                      num_examples - label_array[label_array > t].size(0)]))\n",
    "        m[i] = torch.sqrt(m_k.float())\n",
    "\n",
    "    imp = m/torch.max(m)\n",
    "    return imp\n",
    "\n",
    "\n",
    "# Data-specific scheme\n",
    "if not IMP_WEIGHT:\n",
    "    imp = torch.ones(117-1, dtype=torch.float)\n",
    "elif IMP_WEIGHT == 1:\n",
    "    imp = task_importance_weights(ages)\n",
    "    imp = imp[0:117-1]\n",
    "else:\n",
    "    raise ValueError('Incorrect importance weight parameter.')\n",
    "imp = imp.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af968489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T07:54:41.791204Z",
     "iopub.status.busy": "2023-08-08T07:54:41.790416Z",
     "iopub.status.idle": "2023-08-08T07:54:41.868915Z",
     "shell.execute_reply": "2023-08-08T07:54:41.867868Z"
    },
    "papermill": {
     "duration": 0.086443,
     "end_time": "2023-08-08T07:54:41.871633",
     "exception": false,
     "start_time": "2023-08-08T07:54:41.785190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UTKFace(Dataset):\n",
    "    def __init__(self,\n",
    "                 csv_path, img_dir, transform=None):\n",
    "\n",
    "        df = pd.read_csv(csv_path,)\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.img_names =df[\"filepath\"].values\n",
    "        self.y = df[\"age\"].values\n",
    "        self.z = df[\"gender\"].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label1 = self.y[index]\n",
    "        label2 = self.z[index]\n",
    "        levels = [1]*label1 + [0]*(117 - 1 - label1)\n",
    "        levels = torch.tensor(levels, dtype=torch.float32)\n",
    "\n",
    "        return img, label1, label2, levels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "\n",
    "custom_transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                       transforms.RandomCrop((120, 120)),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "train_dataset = UTKFace(csv_path=TRAIN_CSV_PATH,\n",
    "                              img_dir=os.path.join(IMAGE_PATH,\"Train\"),\n",
    "                              transform=custom_transform)\n",
    "\n",
    "custom_transform2 = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                       transforms.CenterCrop((120, 120)),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "test_dataset =UTKFace(csv_path=TEST_CSV_PATH,\n",
    "                             img_dir=os.path.join(IMAGE_PATH,\"Test\"),\n",
    "                             transform=custom_transform2)\n",
    "\n",
    "valid_dataset = UTKFace(csv_path=VALID_CSV_PATH,\n",
    "                              img_dir=os.path.join(IMAGE_PATH,\"Validation\"),\n",
    "                              transform=custom_transform2)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=NUM_WORKERS)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=NUM_WORKERS)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a29c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T07:54:41.880365Z",
     "iopub.status.busy": "2023-08-08T07:54:41.880051Z",
     "iopub.status.idle": "2023-08-08T07:54:41.903113Z",
     "shell.execute_reply": "2023-08-08T07:54:41.902100Z"
    },
    "papermill": {
     "duration": 0.030258,
     "end_time": "2023-08-08T07:54:41.905481",
     "exception": false,
     "start_time": "2023-08-08T07:54:41.875223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "# MODEL\n",
    "##########################\n",
    "class resnet(ResNet):\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.num_classes=num_classes\n",
    "        self.block=BasicBlock\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(4)\n",
    "        self.fc1 = nn.Linear(512,(self.num_classes-1)*2, bias=True)\n",
    "        self.fc2 = nn.Linear(512, 1, bias=True)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits1 = self.fc1(x)\n",
    "        logits2 = self.fc2(x)\n",
    "        logits1 = logits1.view(-1, (self.num_classes-1), 2)\n",
    "        probas1 = F.softmax(logits1, dim=2)[:, :, 1]\n",
    "        probas2 = torch.sigmoid(logits2)\n",
    "        return logits1, logits2, probas1, probas2\n",
    "\n",
    "\n",
    "def resnet34(num_classes, grayscale):\n",
    "    model=resnet(block=BasicBlock,\n",
    "                   layers=[3, 4, 6, 3],\n",
    "                   num_classes=num_classes,\n",
    "                   grayscale=grayscale)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d7a866e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T07:54:41.913876Z",
     "iopub.status.busy": "2023-08-08T07:54:41.913559Z",
     "iopub.status.idle": "2023-08-08T08:35:33.754876Z",
     "shell.execute_reply": "2023-08-08T08:35:33.753553Z"
    },
    "papermill": {
     "duration": 2451.900717,
     "end_time": "2023-08-08T08:35:33.809486",
     "exception": false,
     "start_time": "2023-08-08T07:54:41.908769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/075 | Batch 0000/0071 | Cost: 93.8835\n",
      "Epoch: 001/075 | Batch 0010/0071 | Cost: 31.1122\n",
      "Epoch: 001/075 | Batch 0020/0071 | Cost: 26.2498\n",
      "Epoch: 001/075 | Batch 0030/0071 | Cost: 23.2961\n",
      "Epoch: 001/075 | Batch 0040/0071 | Cost: 24.0856\n",
      "Epoch: 001/075 | Batch 0050/0071 | Cost: 22.7453\n",
      "Epoch: 001/075 | Batch 0060/0071 | Cost: 22.7406\n",
      "Epoch: 001/075 | Batch 0070/0071 | Cost: 22.1163\n",
      "MAE/RMSE: | Current Valid: 11.18/16.67/60.39 Ep. 0 | Best Valid : 11.18/16.67/60.39 Ep. 0\n",
      "Time elapsed: 0.92 min\n",
      "Epoch: 002/075 | Batch 0000/0071 | Cost: 18.9375\n",
      "Epoch: 002/075 | Batch 0010/0071 | Cost: 21.1801\n",
      "Epoch: 002/075 | Batch 0020/0071 | Cost: 21.0424\n",
      "Epoch: 002/075 | Batch 0030/0071 | Cost: 20.7346\n",
      "Epoch: 002/075 | Batch 0040/0071 | Cost: 18.3981\n",
      "Epoch: 002/075 | Batch 0050/0071 | Cost: 19.8644\n",
      "Epoch: 002/075 | Batch 0060/0071 | Cost: 19.3905\n",
      "Epoch: 002/075 | Batch 0070/0071 | Cost: 17.1345\n",
      "MAE/RMSE: | Current Valid: 33.79/39.31/52.30 Ep. 1 | Best Valid : 11.18/16.67/60.39 Ep. 0\n",
      "Time elapsed: 1.45 min\n",
      "Epoch: 003/075 | Batch 0000/0071 | Cost: 22.5866\n",
      "Epoch: 003/075 | Batch 0010/0071 | Cost: 17.3362\n",
      "Epoch: 003/075 | Batch 0020/0071 | Cost: 17.1721\n",
      "Epoch: 003/075 | Batch 0030/0071 | Cost: 18.2284\n",
      "Epoch: 003/075 | Batch 0040/0071 | Cost: 16.1782\n",
      "Epoch: 003/075 | Batch 0050/0071 | Cost: 16.2606\n",
      "Epoch: 003/075 | Batch 0060/0071 | Cost: 15.0950\n",
      "Epoch: 003/075 | Batch 0070/0071 | Cost: 18.3339\n",
      "MAE/RMSE: | Current Valid: 27.22/33.99/65.12 Ep. 2 | Best Valid : 11.18/16.67/60.39 Ep. 0\n",
      "Time elapsed: 1.98 min\n",
      "Epoch: 004/075 | Batch 0000/0071 | Cost: 18.0928\n",
      "Epoch: 004/075 | Batch 0010/0071 | Cost: 16.9611\n",
      "Epoch: 004/075 | Batch 0020/0071 | Cost: 18.0055\n",
      "Epoch: 004/075 | Batch 0030/0071 | Cost: 15.2422\n",
      "Epoch: 004/075 | Batch 0040/0071 | Cost: 16.5050\n",
      "Epoch: 004/075 | Batch 0050/0071 | Cost: 15.2159\n",
      "Epoch: 004/075 | Batch 0060/0071 | Cost: 15.4285\n",
      "Epoch: 004/075 | Batch 0070/0071 | Cost: 15.4420\n",
      "MAE/RMSE: | Current Valid: 14.72/19.67/72.30 Ep. 3 | Best Valid : 11.18/16.67/60.39 Ep. 0\n",
      "Time elapsed: 2.52 min\n",
      "Epoch: 005/075 | Batch 0000/0071 | Cost: 14.6770\n",
      "Epoch: 005/075 | Batch 0010/0071 | Cost: 14.3742\n",
      "Epoch: 005/075 | Batch 0020/0071 | Cost: 13.9929\n",
      "Epoch: 005/075 | Batch 0030/0071 | Cost: 14.8592\n",
      "Epoch: 005/075 | Batch 0040/0071 | Cost: 14.6932\n",
      "Epoch: 005/075 | Batch 0050/0071 | Cost: 15.4900\n",
      "Epoch: 005/075 | Batch 0060/0071 | Cost: 14.0325\n",
      "Epoch: 005/075 | Batch 0070/0071 | Cost: 18.3267\n",
      "MAE/RMSE: | Current Valid: 29.66/35.51/62.58 Ep. 4 | Best Valid : 11.18/16.67/60.39 Ep. 0\n",
      "Time elapsed: 3.05 min\n",
      "Epoch: 006/075 | Batch 0000/0071 | Cost: 14.5894\n",
      "Epoch: 006/075 | Batch 0010/0071 | Cost: 14.6129\n",
      "Epoch: 006/075 | Batch 0020/0071 | Cost: 15.2967\n",
      "Epoch: 006/075 | Batch 0030/0071 | Cost: 14.6314\n",
      "Epoch: 006/075 | Batch 0040/0071 | Cost: 12.6351\n",
      "Epoch: 006/075 | Batch 0050/0071 | Cost: 14.7247\n",
      "Epoch: 006/075 | Batch 0060/0071 | Cost: 14.0301\n",
      "Epoch: 006/075 | Batch 0070/0071 | Cost: 14.3430\n",
      "MAE/RMSE: | Current Valid: 6.99/9.95/78.95 Ep. 5 | Best Valid : 6.99/9.95/78.95 Ep. 5\n",
      "Time elapsed: 3.58 min\n",
      "Epoch: 007/075 | Batch 0000/0071 | Cost: 14.0062\n",
      "Epoch: 007/075 | Batch 0010/0071 | Cost: 13.4198\n",
      "Epoch: 007/075 | Batch 0020/0071 | Cost: 12.5074\n",
      "Epoch: 007/075 | Batch 0030/0071 | Cost: 15.8663\n",
      "Epoch: 007/075 | Batch 0040/0071 | Cost: 12.8556\n",
      "Epoch: 007/075 | Batch 0050/0071 | Cost: 13.9538\n",
      "Epoch: 007/075 | Batch 0060/0071 | Cost: 13.8681\n",
      "Epoch: 007/075 | Batch 0070/0071 | Cost: 14.6189\n",
      "MAE/RMSE: | Current Valid: 7.32/10.33/80.83 Ep. 6 | Best Valid : 6.99/9.95/78.95 Ep. 5\n",
      "Time elapsed: 4.11 min\n",
      "Epoch: 008/075 | Batch 0000/0071 | Cost: 11.8135\n",
      "Epoch: 008/075 | Batch 0010/0071 | Cost: 14.2189\n",
      "Epoch: 008/075 | Batch 0020/0071 | Cost: 13.4616\n",
      "Epoch: 008/075 | Batch 0030/0071 | Cost: 12.6090\n",
      "Epoch: 008/075 | Batch 0040/0071 | Cost: 13.0696\n",
      "Epoch: 008/075 | Batch 0050/0071 | Cost: 11.4161\n",
      "Epoch: 008/075 | Batch 0060/0071 | Cost: 12.6050\n",
      "Epoch: 008/075 | Batch 0070/0071 | Cost: 12.8126\n",
      "MAE/RMSE: | Current Valid: 6.77/9.87/82.93 Ep. 7 | Best Valid : 6.77/9.87/82.93 Ep. 7\n",
      "Time elapsed: 4.64 min\n",
      "Epoch: 009/075 | Batch 0000/0071 | Cost: 11.8050\n",
      "Epoch: 009/075 | Batch 0010/0071 | Cost: 12.0714\n",
      "Epoch: 009/075 | Batch 0020/0071 | Cost: 12.0263\n",
      "Epoch: 009/075 | Batch 0030/0071 | Cost: 11.5271\n",
      "Epoch: 009/075 | Batch 0040/0071 | Cost: 12.2577\n",
      "Epoch: 009/075 | Batch 0050/0071 | Cost: 12.4673\n",
      "Epoch: 009/075 | Batch 0060/0071 | Cost: 11.9962\n",
      "Epoch: 009/075 | Batch 0070/0071 | Cost: 12.1953\n",
      "MAE/RMSE: | Current Valid: 22.36/28.38/78.82 Ep. 8 | Best Valid : 6.77/9.87/82.93 Ep. 7\n",
      "Time elapsed: 5.17 min\n",
      "Epoch: 010/075 | Batch 0000/0071 | Cost: 12.4519\n",
      "Epoch: 010/075 | Batch 0010/0071 | Cost: 11.7886\n",
      "Epoch: 010/075 | Batch 0020/0071 | Cost: 10.6710\n",
      "Epoch: 010/075 | Batch 0030/0071 | Cost: 11.8389\n",
      "Epoch: 010/075 | Batch 0040/0071 | Cost: 11.5602\n",
      "Epoch: 010/075 | Batch 0050/0071 | Cost: 13.1414\n",
      "Epoch: 010/075 | Batch 0060/0071 | Cost: 12.6101\n",
      "Epoch: 010/075 | Batch 0070/0071 | Cost: 12.5610\n",
      "MAE/RMSE: | Current Valid: 7.07/10.58/84.33 Ep. 9 | Best Valid : 6.77/9.87/82.93 Ep. 7\n",
      "Time elapsed: 5.69 min\n",
      "Epoch: 011/075 | Batch 0000/0071 | Cost: 9.7683\n",
      "Epoch: 011/075 | Batch 0010/0071 | Cost: 11.8855\n",
      "Epoch: 011/075 | Batch 0020/0071 | Cost: 10.2429\n",
      "Epoch: 011/075 | Batch 0030/0071 | Cost: 13.6120\n",
      "Epoch: 011/075 | Batch 0040/0071 | Cost: 12.6513\n",
      "Epoch: 011/075 | Batch 0050/0071 | Cost: 10.8870\n",
      "Epoch: 011/075 | Batch 0060/0071 | Cost: 11.5943\n",
      "Epoch: 011/075 | Batch 0070/0071 | Cost: 12.6713\n",
      "MAE/RMSE: | Current Valid: 32.96/38.67/64.03 Ep. 10 | Best Valid : 6.77/9.87/82.93 Ep. 7\n",
      "Time elapsed: 6.23 min\n",
      "Epoch: 012/075 | Batch 0000/0071 | Cost: 11.0587\n",
      "Epoch: 012/075 | Batch 0010/0071 | Cost: 11.3611\n",
      "Epoch: 012/075 | Batch 0020/0071 | Cost: 10.1545\n",
      "Epoch: 012/075 | Batch 0030/0071 | Cost: 12.0356\n",
      "Epoch: 012/075 | Batch 0040/0071 | Cost: 11.3612\n",
      "Epoch: 012/075 | Batch 0050/0071 | Cost: 12.3366\n",
      "Epoch: 012/075 | Batch 0060/0071 | Cost: 10.9049\n",
      "Epoch: 012/075 | Batch 0070/0071 | Cost: 11.2641\n",
      "MAE/RMSE: | Current Valid: 8.18/11.63/84.95 Ep. 11 | Best Valid : 6.77/9.87/82.93 Ep. 7\n",
      "Time elapsed: 6.75 min\n",
      "Epoch: 013/075 | Batch 0000/0071 | Cost: 10.9095\n",
      "Epoch: 013/075 | Batch 0010/0071 | Cost: 9.3562\n",
      "Epoch: 013/075 | Batch 0020/0071 | Cost: 10.2017\n",
      "Epoch: 013/075 | Batch 0030/0071 | Cost: 9.7948\n",
      "Epoch: 013/075 | Batch 0040/0071 | Cost: 11.3161\n",
      "Epoch: 013/075 | Batch 0050/0071 | Cost: 11.0138\n",
      "Epoch: 013/075 | Batch 0060/0071 | Cost: 11.4333\n",
      "Epoch: 013/075 | Batch 0070/0071 | Cost: 11.1982\n",
      "MAE/RMSE: | Current Valid: 6.27/9.26/85.43 Ep. 12 | Best Valid : 6.27/9.26/85.43 Ep. 12\n",
      "Time elapsed: 7.28 min\n",
      "Epoch: 014/075 | Batch 0000/0071 | Cost: 9.8394\n",
      "Epoch: 014/075 | Batch 0010/0071 | Cost: 9.2348\n",
      "Epoch: 014/075 | Batch 0020/0071 | Cost: 10.3892\n",
      "Epoch: 014/075 | Batch 0030/0071 | Cost: 9.8987\n",
      "Epoch: 014/075 | Batch 0040/0071 | Cost: 10.7244\n",
      "Epoch: 014/075 | Batch 0050/0071 | Cost: 11.0482\n",
      "Epoch: 014/075 | Batch 0060/0071 | Cost: 10.0848\n",
      "Epoch: 014/075 | Batch 0070/0071 | Cost: 9.5670\n",
      "MAE/RMSE: | Current Valid: 15.06/22.14/75.67 Ep. 13 | Best Valid : 6.27/9.26/85.43 Ep. 12\n",
      "Time elapsed: 7.81 min\n",
      "Epoch: 015/075 | Batch 0000/0071 | Cost: 9.3852\n",
      "Epoch: 015/075 | Batch 0010/0071 | Cost: 11.4066\n",
      "Epoch: 015/075 | Batch 0020/0071 | Cost: 9.2972\n",
      "Epoch: 015/075 | Batch 0030/0071 | Cost: 10.5170\n",
      "Epoch: 015/075 | Batch 0040/0071 | Cost: 10.9536\n",
      "Epoch: 015/075 | Batch 0050/0071 | Cost: 9.7339\n",
      "Epoch: 015/075 | Batch 0060/0071 | Cost: 10.1878\n",
      "Epoch: 015/075 | Batch 0070/0071 | Cost: 10.7580\n",
      "MAE/RMSE: | Current Valid: 7.92/11.03/76.41 Ep. 14 | Best Valid : 6.27/9.26/85.43 Ep. 12\n",
      "Time elapsed: 8.32 min\n",
      "Epoch: 016/075 | Batch 0000/0071 | Cost: 9.6224\n",
      "Epoch: 016/075 | Batch 0010/0071 | Cost: 9.1215\n",
      "Epoch: 016/075 | Batch 0020/0071 | Cost: 9.4129\n",
      "Epoch: 016/075 | Batch 0030/0071 | Cost: 9.8999\n",
      "Epoch: 016/075 | Batch 0040/0071 | Cost: 8.2671\n",
      "Epoch: 016/075 | Batch 0050/0071 | Cost: 9.1814\n",
      "Epoch: 016/075 | Batch 0060/0071 | Cost: 10.6174\n",
      "Epoch: 016/075 | Batch 0070/0071 | Cost: 10.4197\n",
      "MAE/RMSE: | Current Valid: 6.20/9.06/78.34 Ep. 15 | Best Valid : 6.20/9.06/78.34 Ep. 15\n",
      "Time elapsed: 8.85 min\n",
      "Epoch: 017/075 | Batch 0000/0071 | Cost: 9.5821\n",
      "Epoch: 017/075 | Batch 0010/0071 | Cost: 8.5600\n",
      "Epoch: 017/075 | Batch 0020/0071 | Cost: 8.6687\n",
      "Epoch: 017/075 | Batch 0030/0071 | Cost: 11.0916\n",
      "Epoch: 017/075 | Batch 0040/0071 | Cost: 8.1991\n",
      "Epoch: 017/075 | Batch 0050/0071 | Cost: 10.2807\n",
      "Epoch: 017/075 | Batch 0060/0071 | Cost: 9.0768\n",
      "Epoch: 017/075 | Batch 0070/0071 | Cost: 10.3185\n",
      "MAE/RMSE: | Current Valid: 6.43/9.37/69.02 Ep. 16 | Best Valid : 6.20/9.06/78.34 Ep. 15\n",
      "Time elapsed: 9.38 min\n",
      "Epoch: 018/075 | Batch 0000/0071 | Cost: 8.5298\n",
      "Epoch: 018/075 | Batch 0010/0071 | Cost: 8.6387\n",
      "Epoch: 018/075 | Batch 0020/0071 | Cost: 8.9538\n",
      "Epoch: 018/075 | Batch 0030/0071 | Cost: 9.3690\n",
      "Epoch: 018/075 | Batch 0040/0071 | Cost: 8.7734\n",
      "Epoch: 018/075 | Batch 0050/0071 | Cost: 9.6403\n",
      "Epoch: 018/075 | Batch 0060/0071 | Cost: 8.8187\n",
      "Epoch: 018/075 | Batch 0070/0071 | Cost: 9.8091\n",
      "MAE/RMSE: | Current Valid: 6.06/9.02/73.70 Ep. 17 | Best Valid : 6.06/9.02/73.70 Ep. 17\n",
      "Time elapsed: 9.90 min\n",
      "Epoch: 019/075 | Batch 0000/0071 | Cost: 8.8183\n",
      "Epoch: 019/075 | Batch 0010/0071 | Cost: 9.3259\n",
      "Epoch: 019/075 | Batch 0020/0071 | Cost: 8.4080\n",
      "Epoch: 019/075 | Batch 0030/0071 | Cost: 8.7378\n",
      "Epoch: 019/075 | Batch 0040/0071 | Cost: 9.0505\n",
      "Epoch: 019/075 | Batch 0050/0071 | Cost: 9.2982\n",
      "Epoch: 019/075 | Batch 0060/0071 | Cost: 9.4195\n",
      "Epoch: 019/075 | Batch 0070/0071 | Cost: 10.5433\n",
      "MAE/RMSE: | Current Valid: 7.19/10.42/84.46 Ep. 18 | Best Valid : 6.06/9.02/73.70 Ep. 17\n",
      "Time elapsed: 10.43 min\n",
      "Epoch: 020/075 | Batch 0000/0071 | Cost: 9.6397\n",
      "Epoch: 020/075 | Batch 0010/0071 | Cost: 7.4011\n",
      "Epoch: 020/075 | Batch 0020/0071 | Cost: 8.2819\n",
      "Epoch: 020/075 | Batch 0030/0071 | Cost: 8.3263\n",
      "Epoch: 020/075 | Batch 0040/0071 | Cost: 7.7441\n",
      "Epoch: 020/075 | Batch 0050/0071 | Cost: 8.6479\n",
      "Epoch: 020/075 | Batch 0060/0071 | Cost: 8.1756\n",
      "Epoch: 020/075 | Batch 0070/0071 | Cost: 9.5153\n",
      "MAE/RMSE: | Current Valid: 6.28/9.11/83.02 Ep. 19 | Best Valid : 6.06/9.02/73.70 Ep. 17\n",
      "Time elapsed: 10.95 min\n",
      "Epoch: 021/075 | Batch 0000/0071 | Cost: 7.7365\n",
      "Epoch: 021/075 | Batch 0010/0071 | Cost: 8.3540\n",
      "Epoch: 021/075 | Batch 0020/0071 | Cost: 7.6317\n",
      "Epoch: 021/075 | Batch 0030/0071 | Cost: 7.8511\n",
      "Epoch: 021/075 | Batch 0040/0071 | Cost: 9.0506\n",
      "Epoch: 021/075 | Batch 0050/0071 | Cost: 9.0681\n",
      "Epoch: 021/075 | Batch 0060/0071 | Cost: 8.4008\n",
      "Epoch: 021/075 | Batch 0070/0071 | Cost: 8.6777\n",
      "MAE/RMSE: | Current Valid: 6.11/8.94/83.33 Ep. 20 | Best Valid : 6.06/9.02/73.70 Ep. 17\n",
      "Time elapsed: 11.47 min\n",
      "Epoch: 022/075 | Batch 0000/0071 | Cost: 7.7798\n",
      "Epoch: 022/075 | Batch 0010/0071 | Cost: 8.4022\n",
      "Epoch: 022/075 | Batch 0020/0071 | Cost: 7.8366\n",
      "Epoch: 022/075 | Batch 0030/0071 | Cost: 7.8372\n",
      "Epoch: 022/075 | Batch 0040/0071 | Cost: 7.7373\n",
      "Epoch: 022/075 | Batch 0050/0071 | Cost: 8.3174\n",
      "Epoch: 022/075 | Batch 0060/0071 | Cost: 8.3976\n",
      "Epoch: 022/075 | Batch 0070/0071 | Cost: 7.1796\n",
      "MAE/RMSE: | Current Valid: 6.12/9.17/85.82 Ep. 21 | Best Valid : 6.06/9.02/73.70 Ep. 17\n",
      "Time elapsed: 12.00 min\n",
      "Epoch: 023/075 | Batch 0000/0071 | Cost: 9.2528\n",
      "Epoch: 023/075 | Batch 0010/0071 | Cost: 6.6776\n",
      "Epoch: 023/075 | Batch 0020/0071 | Cost: 8.1816\n",
      "Epoch: 023/075 | Batch 0030/0071 | Cost: 7.9622\n",
      "Epoch: 023/075 | Batch 0040/0071 | Cost: 7.2742\n",
      "Epoch: 023/075 | Batch 0050/0071 | Cost: 7.0952\n",
      "Epoch: 023/075 | Batch 0060/0071 | Cost: 7.5146\n",
      "Epoch: 023/075 | Batch 0070/0071 | Cost: 8.7008\n",
      "MAE/RMSE: | Current Valid: 6.24/9.10/84.73 Ep. 22 | Best Valid : 6.06/9.02/73.70 Ep. 17\n",
      "Time elapsed: 12.53 min\n",
      "Epoch: 024/075 | Batch 0000/0071 | Cost: 7.5892\n",
      "Epoch: 024/075 | Batch 0010/0071 | Cost: 6.5460\n",
      "Epoch: 024/075 | Batch 0020/0071 | Cost: 6.8861\n",
      "Epoch: 024/075 | Batch 0030/0071 | Cost: 7.5692\n",
      "Epoch: 024/075 | Batch 0040/0071 | Cost: 8.3428\n",
      "Epoch: 024/075 | Batch 0050/0071 | Cost: 7.9662\n",
      "Epoch: 024/075 | Batch 0060/0071 | Cost: 7.2471\n",
      "Epoch: 024/075 | Batch 0070/0071 | Cost: 7.3439\n",
      "MAE/RMSE: | Current Valid: 5.83/8.55/84.77 Ep. 23 | Best Valid : 5.83/8.55/84.77 Ep. 23\n",
      "Time elapsed: 13.05 min\n",
      "Epoch: 025/075 | Batch 0000/0071 | Cost: 6.4333\n",
      "Epoch: 025/075 | Batch 0010/0071 | Cost: 7.9022\n",
      "Epoch: 025/075 | Batch 0020/0071 | Cost: 6.9367\n",
      "Epoch: 025/075 | Batch 0030/0071 | Cost: 8.0479\n",
      "Epoch: 025/075 | Batch 0040/0071 | Cost: 7.9570\n",
      "Epoch: 025/075 | Batch 0050/0071 | Cost: 7.8452\n",
      "Epoch: 025/075 | Batch 0060/0071 | Cost: 8.1814\n",
      "Epoch: 025/075 | Batch 0070/0071 | Cost: 6.8899\n",
      "MAE/RMSE: | Current Valid: 5.69/8.53/84.29 Ep. 24 | Best Valid : 5.69/8.53/84.29 Ep. 24\n",
      "Time elapsed: 13.58 min\n",
      "Epoch: 026/075 | Batch 0000/0071 | Cost: 5.8502\n",
      "Epoch: 026/075 | Batch 0010/0071 | Cost: 6.7418\n",
      "Epoch: 026/075 | Batch 0020/0071 | Cost: 7.4414\n",
      "Epoch: 026/075 | Batch 0030/0071 | Cost: 7.4134\n",
      "Epoch: 026/075 | Batch 0040/0071 | Cost: 7.2832\n",
      "Epoch: 026/075 | Batch 0050/0071 | Cost: 7.4751\n",
      "Epoch: 026/075 | Batch 0060/0071 | Cost: 7.6868\n",
      "Epoch: 026/075 | Batch 0070/0071 | Cost: 8.0080\n",
      "MAE/RMSE: | Current Valid: 5.87/8.72/86.35 Ep. 25 | Best Valid : 5.69/8.53/84.29 Ep. 24\n",
      "Time elapsed: 14.11 min\n",
      "Epoch: 027/075 | Batch 0000/0071 | Cost: 6.4543\n",
      "Epoch: 027/075 | Batch 0010/0071 | Cost: 6.2703\n",
      "Epoch: 027/075 | Batch 0020/0071 | Cost: 7.6997\n",
      "Epoch: 027/075 | Batch 0030/0071 | Cost: 7.0169\n",
      "Epoch: 027/075 | Batch 0040/0071 | Cost: 6.9970\n",
      "Epoch: 027/075 | Batch 0050/0071 | Cost: 7.0281\n",
      "Epoch: 027/075 | Batch 0060/0071 | Cost: 6.5585\n",
      "Epoch: 027/075 | Batch 0070/0071 | Cost: 6.9553\n",
      "MAE/RMSE: | Current Valid: 6.99/10.21/86.13 Ep. 26 | Best Valid : 5.69/8.53/84.29 Ep. 24\n",
      "Time elapsed: 14.63 min\n",
      "Epoch: 028/075 | Batch 0000/0071 | Cost: 6.6698\n",
      "Epoch: 028/075 | Batch 0010/0071 | Cost: 6.0298\n",
      "Epoch: 028/075 | Batch 0020/0071 | Cost: 5.7835\n",
      "Epoch: 028/075 | Batch 0030/0071 | Cost: 5.7633\n",
      "Epoch: 028/075 | Batch 0040/0071 | Cost: 6.3700\n",
      "Epoch: 028/075 | Batch 0050/0071 | Cost: 6.6941\n",
      "Epoch: 028/075 | Batch 0060/0071 | Cost: 7.2324\n",
      "Epoch: 028/075 | Batch 0070/0071 | Cost: 6.3936\n",
      "MAE/RMSE: | Current Valid: 5.60/8.40/86.26 Ep. 27 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 15.17 min\n",
      "Epoch: 029/075 | Batch 0000/0071 | Cost: 6.4979\n",
      "Epoch: 029/075 | Batch 0010/0071 | Cost: 6.2908\n",
      "Epoch: 029/075 | Batch 0020/0071 | Cost: 5.9667\n",
      "Epoch: 029/075 | Batch 0030/0071 | Cost: 6.8260\n",
      "Epoch: 029/075 | Batch 0040/0071 | Cost: 6.1610\n",
      "Epoch: 029/075 | Batch 0050/0071 | Cost: 6.1316\n",
      "Epoch: 029/075 | Batch 0060/0071 | Cost: 6.4104\n",
      "Epoch: 029/075 | Batch 0070/0071 | Cost: 6.2410\n",
      "MAE/RMSE: | Current Valid: 6.24/9.27/84.60 Ep. 28 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 15.70 min\n",
      "Epoch: 030/075 | Batch 0000/0071 | Cost: 6.0120\n",
      "Epoch: 030/075 | Batch 0010/0071 | Cost: 6.8576\n",
      "Epoch: 030/075 | Batch 0020/0071 | Cost: 6.2234\n",
      "Epoch: 030/075 | Batch 0030/0071 | Cost: 6.0363\n",
      "Epoch: 030/075 | Batch 0040/0071 | Cost: 7.1646\n",
      "Epoch: 030/075 | Batch 0050/0071 | Cost: 7.1381\n",
      "Epoch: 030/075 | Batch 0060/0071 | Cost: 6.7079\n",
      "Epoch: 030/075 | Batch 0070/0071 | Cost: 6.2432\n",
      "MAE/RMSE: | Current Valid: 5.97/8.79/80.48 Ep. 29 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 16.23 min\n",
      "Epoch: 031/075 | Batch 0000/0071 | Cost: 6.2362\n",
      "Epoch: 031/075 | Batch 0010/0071 | Cost: 5.8154\n",
      "Epoch: 031/075 | Batch 0020/0071 | Cost: 5.9971\n",
      "Epoch: 031/075 | Batch 0030/0071 | Cost: 5.6568\n",
      "Epoch: 031/075 | Batch 0040/0071 | Cost: 5.5619\n",
      "Epoch: 031/075 | Batch 0050/0071 | Cost: 6.1232\n",
      "Epoch: 031/075 | Batch 0060/0071 | Cost: 6.5103\n",
      "Epoch: 031/075 | Batch 0070/0071 | Cost: 7.0554\n",
      "MAE/RMSE: | Current Valid: 9.16/13.11/83.11 Ep. 30 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 16.75 min\n",
      "Epoch: 032/075 | Batch 0000/0071 | Cost: 5.3064\n",
      "Epoch: 032/075 | Batch 0010/0071 | Cost: 5.2911\n",
      "Epoch: 032/075 | Batch 0020/0071 | Cost: 6.3346\n",
      "Epoch: 032/075 | Batch 0030/0071 | Cost: 6.2490\n",
      "Epoch: 032/075 | Batch 0040/0071 | Cost: 6.0296\n",
      "Epoch: 032/075 | Batch 0050/0071 | Cost: 7.7345\n",
      "Epoch: 032/075 | Batch 0060/0071 | Cost: 5.8882\n",
      "Epoch: 032/075 | Batch 0070/0071 | Cost: 6.0489\n",
      "MAE/RMSE: | Current Valid: 5.92/9.10/85.78 Ep. 31 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 17.28 min\n",
      "Epoch: 033/075 | Batch 0000/0071 | Cost: 5.8260\n",
      "Epoch: 033/075 | Batch 0010/0071 | Cost: 6.3480\n",
      "Epoch: 033/075 | Batch 0020/0071 | Cost: 6.1494\n",
      "Epoch: 033/075 | Batch 0030/0071 | Cost: 5.3859\n",
      "Epoch: 033/075 | Batch 0040/0071 | Cost: 5.7339\n",
      "Epoch: 033/075 | Batch 0050/0071 | Cost: 6.4498\n",
      "Epoch: 033/075 | Batch 0060/0071 | Cost: 6.1607\n",
      "Epoch: 033/075 | Batch 0070/0071 | Cost: 5.6218\n",
      "MAE/RMSE: | Current Valid: 6.42/9.11/86.65 Ep. 32 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 17.81 min\n",
      "Epoch: 034/075 | Batch 0000/0071 | Cost: 5.9315\n",
      "Epoch: 034/075 | Batch 0010/0071 | Cost: 5.6813\n",
      "Epoch: 034/075 | Batch 0020/0071 | Cost: 5.4371\n",
      "Epoch: 034/075 | Batch 0030/0071 | Cost: 5.5650\n",
      "Epoch: 034/075 | Batch 0040/0071 | Cost: 6.2066\n",
      "Epoch: 034/075 | Batch 0050/0071 | Cost: 5.3730\n",
      "Epoch: 034/075 | Batch 0060/0071 | Cost: 4.8823\n",
      "Epoch: 034/075 | Batch 0070/0071 | Cost: 5.5753\n",
      "MAE/RMSE: | Current Valid: 11.10/16.21/83.46 Ep. 33 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 18.34 min\n",
      "Epoch: 035/075 | Batch 0000/0071 | Cost: 4.9425\n",
      "Epoch: 035/075 | Batch 0010/0071 | Cost: 5.1412\n",
      "Epoch: 035/075 | Batch 0020/0071 | Cost: 6.0756\n",
      "Epoch: 035/075 | Batch 0030/0071 | Cost: 5.1178\n",
      "Epoch: 035/075 | Batch 0040/0071 | Cost: 5.4388\n",
      "Epoch: 035/075 | Batch 0050/0071 | Cost: 5.3220\n",
      "Epoch: 035/075 | Batch 0060/0071 | Cost: 5.7296\n",
      "Epoch: 035/075 | Batch 0070/0071 | Cost: 5.2967\n",
      "MAE/RMSE: | Current Valid: 6.02/8.74/86.48 Ep. 34 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 18.88 min\n",
      "Epoch: 036/075 | Batch 0000/0071 | Cost: 4.9113\n",
      "Epoch: 036/075 | Batch 0010/0071 | Cost: 5.2336\n",
      "Epoch: 036/075 | Batch 0020/0071 | Cost: 5.1943\n",
      "Epoch: 036/075 | Batch 0030/0071 | Cost: 5.2352\n",
      "Epoch: 036/075 | Batch 0040/0071 | Cost: 5.2477\n",
      "Epoch: 036/075 | Batch 0050/0071 | Cost: 5.7211\n",
      "Epoch: 036/075 | Batch 0060/0071 | Cost: 5.1703\n",
      "Epoch: 036/075 | Batch 0070/0071 | Cost: 5.2647\n",
      "MAE/RMSE: | Current Valid: 5.69/8.39/85.65 Ep. 35 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 19.41 min\n",
      "Epoch: 037/075 | Batch 0000/0071 | Cost: 6.0217\n",
      "Epoch: 037/075 | Batch 0010/0071 | Cost: 5.3957\n",
      "Epoch: 037/075 | Batch 0020/0071 | Cost: 5.6082\n",
      "Epoch: 037/075 | Batch 0030/0071 | Cost: 5.8678\n",
      "Epoch: 037/075 | Batch 0040/0071 | Cost: 5.1584\n",
      "Epoch: 037/075 | Batch 0050/0071 | Cost: 5.0468\n",
      "Epoch: 037/075 | Batch 0060/0071 | Cost: 5.9390\n",
      "Epoch: 037/075 | Batch 0070/0071 | Cost: 5.4106\n",
      "MAE/RMSE: | Current Valid: 5.70/8.23/86.61 Ep. 36 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 19.94 min\n",
      "Epoch: 038/075 | Batch 0000/0071 | Cost: 5.2280\n",
      "Epoch: 038/075 | Batch 0010/0071 | Cost: 5.7003\n",
      "Epoch: 038/075 | Batch 0020/0071 | Cost: 5.8661\n",
      "Epoch: 038/075 | Batch 0030/0071 | Cost: 5.0179\n",
      "Epoch: 038/075 | Batch 0040/0071 | Cost: 5.5585\n",
      "Epoch: 038/075 | Batch 0050/0071 | Cost: 5.7686\n",
      "Epoch: 038/075 | Batch 0060/0071 | Cost: 5.5518\n",
      "Epoch: 038/075 | Batch 0070/0071 | Cost: 5.3956\n",
      "MAE/RMSE: | Current Valid: 7.62/10.58/84.29 Ep. 37 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 20.47 min\n",
      "Epoch: 039/075 | Batch 0000/0071 | Cost: 4.6798\n",
      "Epoch: 039/075 | Batch 0010/0071 | Cost: 5.3422\n",
      "Epoch: 039/075 | Batch 0020/0071 | Cost: 4.5071\n",
      "Epoch: 039/075 | Batch 0030/0071 | Cost: 5.1843\n",
      "Epoch: 039/075 | Batch 0040/0071 | Cost: 4.2756\n",
      "Epoch: 039/075 | Batch 0050/0071 | Cost: 4.6143\n",
      "Epoch: 039/075 | Batch 0060/0071 | Cost: 4.8213\n",
      "Epoch: 039/075 | Batch 0070/0071 | Cost: 7.3548\n",
      "MAE/RMSE: | Current Valid: 5.86/8.74/84.03 Ep. 38 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 20.99 min\n",
      "Epoch: 040/075 | Batch 0000/0071 | Cost: 4.5980\n",
      "Epoch: 040/075 | Batch 0010/0071 | Cost: 5.7610\n",
      "Epoch: 040/075 | Batch 0020/0071 | Cost: 4.7472\n",
      "Epoch: 040/075 | Batch 0030/0071 | Cost: 5.2359\n",
      "Epoch: 040/075 | Batch 0040/0071 | Cost: 4.5256\n",
      "Epoch: 040/075 | Batch 0050/0071 | Cost: 4.4640\n",
      "Epoch: 040/075 | Batch 0060/0071 | Cost: 5.4891\n",
      "Epoch: 040/075 | Batch 0070/0071 | Cost: 5.4077\n",
      "MAE/RMSE: | Current Valid: 7.29/10.85/85.60 Ep. 39 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 21.53 min\n",
      "Epoch: 041/075 | Batch 0000/0071 | Cost: 4.4397\n",
      "Epoch: 041/075 | Batch 0010/0071 | Cost: 4.6575\n",
      "Epoch: 041/075 | Batch 0020/0071 | Cost: 4.5332\n",
      "Epoch: 041/075 | Batch 0030/0071 | Cost: 4.7669\n",
      "Epoch: 041/075 | Batch 0040/0071 | Cost: 4.7856\n",
      "Epoch: 041/075 | Batch 0050/0071 | Cost: 4.5256\n",
      "Epoch: 041/075 | Batch 0060/0071 | Cost: 4.8514\n",
      "Epoch: 041/075 | Batch 0070/0071 | Cost: 5.1539\n",
      "MAE/RMSE: | Current Valid: 5.91/8.42/83.76 Ep. 40 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 22.06 min\n",
      "Epoch: 042/075 | Batch 0000/0071 | Cost: 4.7559\n",
      "Epoch: 042/075 | Batch 0010/0071 | Cost: 4.9242\n",
      "Epoch: 042/075 | Batch 0020/0071 | Cost: 4.3003\n",
      "Epoch: 042/075 | Batch 0030/0071 | Cost: 4.6691\n",
      "Epoch: 042/075 | Batch 0040/0071 | Cost: 4.1094\n",
      "Epoch: 042/075 | Batch 0050/0071 | Cost: 4.6955\n",
      "Epoch: 042/075 | Batch 0060/0071 | Cost: 4.5342\n",
      "Epoch: 042/075 | Batch 0070/0071 | Cost: 4.3879\n",
      "MAE/RMSE: | Current Valid: 6.07/8.70/86.30 Ep. 41 | Best Valid : 5.60/8.40/86.26 Ep. 27\n",
      "Time elapsed: 22.58 min\n",
      "Epoch: 043/075 | Batch 0000/0071 | Cost: 4.3676\n",
      "Epoch: 043/075 | Batch 0010/0071 | Cost: 5.4839\n",
      "Epoch: 043/075 | Batch 0020/0071 | Cost: 4.8816\n",
      "Epoch: 043/075 | Batch 0030/0071 | Cost: 5.2923\n",
      "Epoch: 043/075 | Batch 0040/0071 | Cost: 4.9270\n",
      "Epoch: 043/075 | Batch 0050/0071 | Cost: 4.2790\n",
      "Epoch: 043/075 | Batch 0060/0071 | Cost: 4.7064\n",
      "Epoch: 043/075 | Batch 0070/0071 | Cost: 4.0534\n",
      "MAE/RMSE: | Current Valid: 5.57/8.24/87.96 Ep. 42 | Best Valid : 5.57/8.24/87.96 Ep. 42\n",
      "Time elapsed: 23.12 min\n",
      "Epoch: 044/075 | Batch 0000/0071 | Cost: 3.9477\n",
      "Epoch: 044/075 | Batch 0010/0071 | Cost: 3.8861\n",
      "Epoch: 044/075 | Batch 0020/0071 | Cost: 4.5921\n",
      "Epoch: 044/075 | Batch 0030/0071 | Cost: 4.4884\n",
      "Epoch: 044/075 | Batch 0040/0071 | Cost: 4.8631\n",
      "Epoch: 044/075 | Batch 0050/0071 | Cost: 3.8115\n",
      "Epoch: 044/075 | Batch 0060/0071 | Cost: 4.3875\n",
      "Epoch: 044/075 | Batch 0070/0071 | Cost: 4.3858\n",
      "MAE/RMSE: | Current Valid: 5.84/8.90/87.13 Ep. 43 | Best Valid : 5.57/8.24/87.96 Ep. 42\n",
      "Time elapsed: 23.65 min\n",
      "Epoch: 045/075 | Batch 0000/0071 | Cost: 4.2232\n",
      "Epoch: 045/075 | Batch 0010/0071 | Cost: 4.0019\n",
      "Epoch: 045/075 | Batch 0020/0071 | Cost: 4.3661\n",
      "Epoch: 045/075 | Batch 0030/0071 | Cost: 4.1767\n",
      "Epoch: 045/075 | Batch 0040/0071 | Cost: 4.2977\n",
      "Epoch: 045/075 | Batch 0050/0071 | Cost: 4.4278\n",
      "Epoch: 045/075 | Batch 0060/0071 | Cost: 4.1318\n",
      "Epoch: 045/075 | Batch 0070/0071 | Cost: 4.5990\n",
      "MAE/RMSE: | Current Valid: 5.71/8.21/88.01 Ep. 44 | Best Valid : 5.57/8.24/87.96 Ep. 42\n",
      "Time elapsed: 24.17 min\n",
      "Epoch: 046/075 | Batch 0000/0071 | Cost: 4.3318\n",
      "Epoch: 046/075 | Batch 0010/0071 | Cost: 3.9887\n",
      "Epoch: 046/075 | Batch 0020/0071 | Cost: 4.2259\n",
      "Epoch: 046/075 | Batch 0030/0071 | Cost: 4.3369\n",
      "Epoch: 046/075 | Batch 0040/0071 | Cost: 4.2689\n",
      "Epoch: 046/075 | Batch 0050/0071 | Cost: 4.4826\n",
      "Epoch: 046/075 | Batch 0060/0071 | Cost: 4.9036\n",
      "Epoch: 046/075 | Batch 0070/0071 | Cost: 4.1840\n",
      "MAE/RMSE: | Current Valid: 5.62/8.25/87.05 Ep. 45 | Best Valid : 5.57/8.24/87.96 Ep. 42\n",
      "Time elapsed: 24.70 min\n",
      "Epoch: 047/075 | Batch 0000/0071 | Cost: 5.5942\n",
      "Epoch: 047/075 | Batch 0010/0071 | Cost: 4.0908\n",
      "Epoch: 047/075 | Batch 0020/0071 | Cost: 3.7327\n",
      "Epoch: 047/075 | Batch 0030/0071 | Cost: 4.5209\n",
      "Epoch: 047/075 | Batch 0040/0071 | Cost: 4.4950\n",
      "Epoch: 047/075 | Batch 0050/0071 | Cost: 4.5261\n",
      "Epoch: 047/075 | Batch 0060/0071 | Cost: 4.2936\n",
      "Epoch: 047/075 | Batch 0070/0071 | Cost: 4.3395\n",
      "MAE/RMSE: | Current Valid: 6.59/9.80/86.00 Ep. 46 | Best Valid : 5.57/8.24/87.96 Ep. 42\n",
      "Time elapsed: 25.23 min\n",
      "Epoch: 048/075 | Batch 0000/0071 | Cost: 3.8497\n",
      "Epoch: 048/075 | Batch 0010/0071 | Cost: 4.2817\n",
      "Epoch: 048/075 | Batch 0020/0071 | Cost: 4.3044\n",
      "Epoch: 048/075 | Batch 0030/0071 | Cost: 3.8219\n",
      "Epoch: 048/075 | Batch 0040/0071 | Cost: 3.6028\n",
      "Epoch: 048/075 | Batch 0050/0071 | Cost: 4.2816\n",
      "Epoch: 048/075 | Batch 0060/0071 | Cost: 4.0322\n",
      "Epoch: 048/075 | Batch 0070/0071 | Cost: 4.1462\n",
      "MAE/RMSE: | Current Valid: 5.52/8.02/87.92 Ep. 47 | Best Valid : 5.52/8.02/87.92 Ep. 47\n",
      "Time elapsed: 25.77 min\n",
      "Epoch: 049/075 | Batch 0000/0071 | Cost: 4.0320\n",
      "Epoch: 049/075 | Batch 0010/0071 | Cost: 4.3713\n",
      "Epoch: 049/075 | Batch 0020/0071 | Cost: 4.0999\n",
      "Epoch: 049/075 | Batch 0030/0071 | Cost: 3.9969\n",
      "Epoch: 049/075 | Batch 0040/0071 | Cost: 3.5560\n",
      "Epoch: 049/075 | Batch 0050/0071 | Cost: 3.8636\n",
      "Epoch: 049/075 | Batch 0060/0071 | Cost: 3.3171\n",
      "Epoch: 049/075 | Batch 0070/0071 | Cost: 4.0077\n",
      "MAE/RMSE: | Current Valid: 6.66/9.40/88.80 Ep. 48 | Best Valid : 5.52/8.02/87.92 Ep. 47\n",
      "Time elapsed: 26.30 min\n",
      "Epoch: 050/075 | Batch 0000/0071 | Cost: 3.9083\n",
      "Epoch: 050/075 | Batch 0010/0071 | Cost: 4.1728\n",
      "Epoch: 050/075 | Batch 0020/0071 | Cost: 5.6616\n",
      "Epoch: 050/075 | Batch 0030/0071 | Cost: 3.9055\n",
      "Epoch: 050/075 | Batch 0040/0071 | Cost: 3.5555\n",
      "Epoch: 050/075 | Batch 0050/0071 | Cost: 4.1403\n",
      "Epoch: 050/075 | Batch 0060/0071 | Cost: 4.6367\n",
      "Epoch: 050/075 | Batch 0070/0071 | Cost: 3.6647\n",
      "MAE/RMSE: | Current Valid: 5.74/8.45/88.27 Ep. 49 | Best Valid : 5.52/8.02/87.92 Ep. 47\n",
      "Time elapsed: 26.83 min\n",
      "Epoch: 051/075 | Batch 0000/0071 | Cost: 3.5369\n",
      "Epoch: 051/075 | Batch 0010/0071 | Cost: 3.8247\n",
      "Epoch: 051/075 | Batch 0020/0071 | Cost: 4.2088\n",
      "Epoch: 051/075 | Batch 0030/0071 | Cost: 4.4132\n",
      "Epoch: 051/075 | Batch 0040/0071 | Cost: 3.9564\n",
      "Epoch: 051/075 | Batch 0050/0071 | Cost: 3.5767\n",
      "Epoch: 051/075 | Batch 0060/0071 | Cost: 3.9866\n",
      "Epoch: 051/075 | Batch 0070/0071 | Cost: 3.6054\n",
      "MAE/RMSE: | Current Valid: 6.53/9.73/86.17 Ep. 50 | Best Valid : 5.52/8.02/87.92 Ep. 47\n",
      "Time elapsed: 27.36 min\n",
      "Epoch: 052/075 | Batch 0000/0071 | Cost: 4.5092\n",
      "Epoch: 052/075 | Batch 0010/0071 | Cost: 3.6462\n",
      "Epoch: 052/075 | Batch 0020/0071 | Cost: 3.1236\n",
      "Epoch: 052/075 | Batch 0030/0071 | Cost: 3.7083\n",
      "Epoch: 052/075 | Batch 0040/0071 | Cost: 3.6566\n",
      "Epoch: 052/075 | Batch 0050/0071 | Cost: 4.0368\n",
      "Epoch: 052/075 | Batch 0060/0071 | Cost: 4.2858\n",
      "Epoch: 052/075 | Batch 0070/0071 | Cost: 3.7190\n",
      "MAE/RMSE: | Current Valid: 5.48/8.21/87.53 Ep. 51 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 27.88 min\n",
      "Epoch: 053/075 | Batch 0000/0071 | Cost: 3.2872\n",
      "Epoch: 053/075 | Batch 0010/0071 | Cost: 3.4824\n",
      "Epoch: 053/075 | Batch 0020/0071 | Cost: 3.2406\n",
      "Epoch: 053/075 | Batch 0030/0071 | Cost: 3.8448\n",
      "Epoch: 053/075 | Batch 0040/0071 | Cost: 3.1890\n",
      "Epoch: 053/075 | Batch 0050/0071 | Cost: 3.2998\n",
      "Epoch: 053/075 | Batch 0060/0071 | Cost: 3.8944\n",
      "Epoch: 053/075 | Batch 0070/0071 | Cost: 4.2948\n",
      "MAE/RMSE: | Current Valid: 6.36/8.94/88.01 Ep. 52 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 28.41 min\n",
      "Epoch: 054/075 | Batch 0000/0071 | Cost: 3.5032\n",
      "Epoch: 054/075 | Batch 0010/0071 | Cost: 3.2536\n",
      "Epoch: 054/075 | Batch 0020/0071 | Cost: 3.5270\n",
      "Epoch: 054/075 | Batch 0030/0071 | Cost: 3.5301\n",
      "Epoch: 054/075 | Batch 0040/0071 | Cost: 3.6294\n",
      "Epoch: 054/075 | Batch 0050/0071 | Cost: 4.2489\n",
      "Epoch: 054/075 | Batch 0060/0071 | Cost: 3.7398\n",
      "Epoch: 054/075 | Batch 0070/0071 | Cost: 3.8533\n",
      "MAE/RMSE: | Current Valid: 12.22/17.54/82.23 Ep. 53 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 28.94 min\n",
      "Epoch: 055/075 | Batch 0000/0071 | Cost: 3.5697\n",
      "Epoch: 055/075 | Batch 0010/0071 | Cost: 3.6748\n",
      "Epoch: 055/075 | Batch 0020/0071 | Cost: 3.4544\n",
      "Epoch: 055/075 | Batch 0030/0071 | Cost: 3.3207\n",
      "Epoch: 055/075 | Batch 0040/0071 | Cost: 3.8716\n",
      "Epoch: 055/075 | Batch 0050/0071 | Cost: 3.6180\n",
      "Epoch: 055/075 | Batch 0060/0071 | Cost: 4.1754\n",
      "Epoch: 055/075 | Batch 0070/0071 | Cost: 3.5467\n",
      "MAE/RMSE: | Current Valid: 8.99/13.52/85.91 Ep. 54 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 29.46 min\n",
      "Epoch: 056/075 | Batch 0000/0071 | Cost: 3.0475\n",
      "Epoch: 056/075 | Batch 0010/0071 | Cost: 3.6156\n",
      "Epoch: 056/075 | Batch 0020/0071 | Cost: 4.2424\n",
      "Epoch: 056/075 | Batch 0030/0071 | Cost: 3.5851\n",
      "Epoch: 056/075 | Batch 0040/0071 | Cost: 3.2656\n",
      "Epoch: 056/075 | Batch 0050/0071 | Cost: 3.8875\n",
      "Epoch: 056/075 | Batch 0060/0071 | Cost: 3.1889\n",
      "Epoch: 056/075 | Batch 0070/0071 | Cost: 4.0409\n",
      "MAE/RMSE: | Current Valid: 5.77/8.61/88.32 Ep. 55 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 30.00 min\n",
      "Epoch: 057/075 | Batch 0000/0071 | Cost: 3.6221\n",
      "Epoch: 057/075 | Batch 0010/0071 | Cost: 3.0977\n",
      "Epoch: 057/075 | Batch 0020/0071 | Cost: 3.2643\n",
      "Epoch: 057/075 | Batch 0030/0071 | Cost: 3.2245\n",
      "Epoch: 057/075 | Batch 0040/0071 | Cost: 3.1680\n",
      "Epoch: 057/075 | Batch 0050/0071 | Cost: 3.0642\n",
      "Epoch: 057/075 | Batch 0060/0071 | Cost: 3.5413\n",
      "Epoch: 057/075 | Batch 0070/0071 | Cost: 3.4441\n",
      "MAE/RMSE: | Current Valid: 5.61/8.09/88.01 Ep. 56 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 30.52 min\n",
      "Epoch: 058/075 | Batch 0000/0071 | Cost: 2.9723\n",
      "Epoch: 058/075 | Batch 0010/0071 | Cost: 3.4860\n",
      "Epoch: 058/075 | Batch 0020/0071 | Cost: 3.3620\n",
      "Epoch: 058/075 | Batch 0030/0071 | Cost: 3.2648\n",
      "Epoch: 058/075 | Batch 0040/0071 | Cost: 3.1564\n",
      "Epoch: 058/075 | Batch 0050/0071 | Cost: 3.1452\n",
      "Epoch: 058/075 | Batch 0060/0071 | Cost: 3.2502\n",
      "Epoch: 058/075 | Batch 0070/0071 | Cost: 3.7370\n",
      "MAE/RMSE: | Current Valid: 5.76/8.31/88.62 Ep. 57 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 31.05 min\n",
      "Epoch: 059/075 | Batch 0000/0071 | Cost: 2.7902\n",
      "Epoch: 059/075 | Batch 0010/0071 | Cost: 3.1088\n",
      "Epoch: 059/075 | Batch 0020/0071 | Cost: 2.5525\n",
      "Epoch: 059/075 | Batch 0030/0071 | Cost: 3.2996\n",
      "Epoch: 059/075 | Batch 0040/0071 | Cost: 2.7700\n",
      "Epoch: 059/075 | Batch 0050/0071 | Cost: 3.6654\n",
      "Epoch: 059/075 | Batch 0060/0071 | Cost: 3.4971\n",
      "Epoch: 059/075 | Batch 0070/0071 | Cost: 3.1453\n",
      "MAE/RMSE: | Current Valid: 5.74/8.24/89.06 Ep. 58 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 31.59 min\n",
      "Epoch: 060/075 | Batch 0000/0071 | Cost: 2.9601\n",
      "Epoch: 060/075 | Batch 0010/0071 | Cost: 3.7498\n",
      "Epoch: 060/075 | Batch 0020/0071 | Cost: 2.9755\n",
      "Epoch: 060/075 | Batch 0030/0071 | Cost: 2.9226\n",
      "Epoch: 060/075 | Batch 0040/0071 | Cost: 3.0999\n",
      "Epoch: 060/075 | Batch 0050/0071 | Cost: 3.3786\n",
      "Epoch: 060/075 | Batch 0060/0071 | Cost: 3.2725\n",
      "Epoch: 060/075 | Batch 0070/0071 | Cost: 3.4750\n",
      "MAE/RMSE: | Current Valid: 5.87/8.86/86.21 Ep. 59 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 32.13 min\n",
      "Epoch: 061/075 | Batch 0000/0071 | Cost: 3.4113\n",
      "Epoch: 061/075 | Batch 0010/0071 | Cost: 2.8093\n",
      "Epoch: 061/075 | Batch 0020/0071 | Cost: 3.2034\n",
      "Epoch: 061/075 | Batch 0030/0071 | Cost: 3.1625\n",
      "Epoch: 061/075 | Batch 0040/0071 | Cost: 2.8462\n",
      "Epoch: 061/075 | Batch 0050/0071 | Cost: 3.0639\n",
      "Epoch: 061/075 | Batch 0060/0071 | Cost: 3.8091\n",
      "Epoch: 061/075 | Batch 0070/0071 | Cost: 3.6912\n",
      "MAE/RMSE: | Current Valid: 6.05/8.90/86.52 Ep. 60 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 32.68 min\n",
      "Epoch: 062/075 | Batch 0000/0071 | Cost: 3.5022\n",
      "Epoch: 062/075 | Batch 0010/0071 | Cost: 3.5734\n",
      "Epoch: 062/075 | Batch 0020/0071 | Cost: 2.6819\n",
      "Epoch: 062/075 | Batch 0030/0071 | Cost: 3.1022\n",
      "Epoch: 062/075 | Batch 0040/0071 | Cost: 3.2695\n",
      "Epoch: 062/075 | Batch 0050/0071 | Cost: 3.3171\n",
      "Epoch: 062/075 | Batch 0060/0071 | Cost: 2.7006\n",
      "Epoch: 062/075 | Batch 0070/0071 | Cost: 2.8072\n",
      "MAE/RMSE: | Current Valid: 5.65/8.26/86.30 Ep. 61 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 33.22 min\n",
      "Epoch: 063/075 | Batch 0000/0071 | Cost: 2.7639\n",
      "Epoch: 063/075 | Batch 0010/0071 | Cost: 2.7092\n",
      "Epoch: 063/075 | Batch 0020/0071 | Cost: 2.7936\n",
      "Epoch: 063/075 | Batch 0030/0071 | Cost: 2.5903\n",
      "Epoch: 063/075 | Batch 0040/0071 | Cost: 3.8451\n",
      "Epoch: 063/075 | Batch 0050/0071 | Cost: 2.5509\n",
      "Epoch: 063/075 | Batch 0060/0071 | Cost: 2.8478\n",
      "Epoch: 063/075 | Batch 0070/0071 | Cost: 3.0355\n",
      "MAE/RMSE: | Current Valid: 5.65/8.14/88.01 Ep. 62 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 33.76 min\n",
      "Epoch: 064/075 | Batch 0000/0071 | Cost: 3.3981\n",
      "Epoch: 064/075 | Batch 0010/0071 | Cost: 3.2552\n",
      "Epoch: 064/075 | Batch 0020/0071 | Cost: 2.8441\n",
      "Epoch: 064/075 | Batch 0030/0071 | Cost: 2.6638\n",
      "Epoch: 064/075 | Batch 0040/0071 | Cost: 3.2903\n",
      "Epoch: 064/075 | Batch 0050/0071 | Cost: 3.7672\n",
      "Epoch: 064/075 | Batch 0060/0071 | Cost: 2.3813\n",
      "Epoch: 064/075 | Batch 0070/0071 | Cost: 2.7009\n",
      "MAE/RMSE: | Current Valid: 5.63/8.14/87.22 Ep. 63 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 34.30 min\n",
      "Epoch: 065/075 | Batch 0000/0071 | Cost: 2.4590\n",
      "Epoch: 065/075 | Batch 0010/0071 | Cost: 2.6973\n",
      "Epoch: 065/075 | Batch 0020/0071 | Cost: 2.8817\n",
      "Epoch: 065/075 | Batch 0030/0071 | Cost: 2.7324\n",
      "Epoch: 065/075 | Batch 0040/0071 | Cost: 2.6242\n",
      "Epoch: 065/075 | Batch 0050/0071 | Cost: 2.7212\n",
      "Epoch: 065/075 | Batch 0060/0071 | Cost: 3.1229\n",
      "Epoch: 065/075 | Batch 0070/0071 | Cost: 3.2588\n",
      "MAE/RMSE: | Current Valid: 5.50/8.09/87.31 Ep. 64 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 34.84 min\n",
      "Epoch: 066/075 | Batch 0000/0071 | Cost: 2.3820\n",
      "Epoch: 066/075 | Batch 0010/0071 | Cost: 2.8174\n",
      "Epoch: 066/075 | Batch 0020/0071 | Cost: 2.7069\n",
      "Epoch: 066/075 | Batch 0030/0071 | Cost: 2.4539\n",
      "Epoch: 066/075 | Batch 0040/0071 | Cost: 2.8323\n",
      "Epoch: 066/075 | Batch 0050/0071 | Cost: 2.7072\n",
      "Epoch: 066/075 | Batch 0060/0071 | Cost: 3.8905\n",
      "Epoch: 066/075 | Batch 0070/0071 | Cost: 2.8578\n",
      "MAE/RMSE: | Current Valid: 5.53/8.20/86.48 Ep. 65 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 35.39 min\n",
      "Epoch: 067/075 | Batch 0000/0071 | Cost: 2.6054\n",
      "Epoch: 067/075 | Batch 0010/0071 | Cost: 2.8528\n",
      "Epoch: 067/075 | Batch 0020/0071 | Cost: 3.3027\n",
      "Epoch: 067/075 | Batch 0030/0071 | Cost: 2.8778\n",
      "Epoch: 067/075 | Batch 0040/0071 | Cost: 2.7667\n",
      "Epoch: 067/075 | Batch 0050/0071 | Cost: 2.9976\n",
      "Epoch: 067/075 | Batch 0060/0071 | Cost: 3.0475\n",
      "Epoch: 067/075 | Batch 0070/0071 | Cost: 3.2431\n",
      "MAE/RMSE: | Current Valid: 5.57/8.36/87.96 Ep. 66 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 35.92 min\n",
      "Epoch: 068/075 | Batch 0000/0071 | Cost: 2.3756\n",
      "Epoch: 068/075 | Batch 0010/0071 | Cost: 2.4031\n",
      "Epoch: 068/075 | Batch 0020/0071 | Cost: 2.4772\n",
      "Epoch: 068/075 | Batch 0030/0071 | Cost: 2.8951\n",
      "Epoch: 068/075 | Batch 0040/0071 | Cost: 3.1056\n",
      "Epoch: 068/075 | Batch 0050/0071 | Cost: 2.4721\n",
      "Epoch: 068/075 | Batch 0060/0071 | Cost: 2.7141\n",
      "Epoch: 068/075 | Batch 0070/0071 | Cost: 3.2332\n",
      "MAE/RMSE: | Current Valid: 7.63/10.89/88.10 Ep. 67 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 36.46 min\n",
      "Epoch: 069/075 | Batch 0000/0071 | Cost: 2.4065\n",
      "Epoch: 069/075 | Batch 0010/0071 | Cost: 2.3617\n",
      "Epoch: 069/075 | Batch 0020/0071 | Cost: 2.4841\n",
      "Epoch: 069/075 | Batch 0030/0071 | Cost: 2.2532\n",
      "Epoch: 069/075 | Batch 0040/0071 | Cost: 2.9153\n",
      "Epoch: 069/075 | Batch 0050/0071 | Cost: 2.9909\n",
      "Epoch: 069/075 | Batch 0060/0071 | Cost: 2.5425\n",
      "Epoch: 069/075 | Batch 0070/0071 | Cost: 2.3642\n",
      "MAE/RMSE: | Current Valid: 6.33/9.32/86.65 Ep. 68 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 37.01 min\n",
      "Epoch: 070/075 | Batch 0000/0071 | Cost: 2.1836\n",
      "Epoch: 070/075 | Batch 0010/0071 | Cost: 2.3157\n",
      "Epoch: 070/075 | Batch 0020/0071 | Cost: 2.9711\n",
      "Epoch: 070/075 | Batch 0030/0071 | Cost: 2.4739\n",
      "Epoch: 070/075 | Batch 0040/0071 | Cost: 2.3556\n",
      "Epoch: 070/075 | Batch 0050/0071 | Cost: 2.6506\n",
      "Epoch: 070/075 | Batch 0060/0071 | Cost: 2.6457\n",
      "Epoch: 070/075 | Batch 0070/0071 | Cost: 2.3597\n",
      "MAE/RMSE: | Current Valid: 5.54/8.23/88.53 Ep. 69 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 37.56 min\n",
      "Epoch: 071/075 | Batch 0000/0071 | Cost: 2.2952\n",
      "Epoch: 071/075 | Batch 0010/0071 | Cost: 1.8342\n",
      "Epoch: 071/075 | Batch 0020/0071 | Cost: 2.4125\n",
      "Epoch: 071/075 | Batch 0030/0071 | Cost: 2.2502\n",
      "Epoch: 071/075 | Batch 0040/0071 | Cost: 2.4266\n",
      "Epoch: 071/075 | Batch 0050/0071 | Cost: 2.4199\n",
      "Epoch: 071/075 | Batch 0060/0071 | Cost: 2.2934\n",
      "Epoch: 071/075 | Batch 0070/0071 | Cost: 2.5222\n",
      "MAE/RMSE: | Current Valid: 5.89/8.69/88.40 Ep. 70 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 38.12 min\n",
      "Epoch: 072/075 | Batch 0000/0071 | Cost: 2.1774\n",
      "Epoch: 072/075 | Batch 0010/0071 | Cost: 2.0604\n",
      "Epoch: 072/075 | Batch 0020/0071 | Cost: 2.4261\n",
      "Epoch: 072/075 | Batch 0030/0071 | Cost: 2.5995\n",
      "Epoch: 072/075 | Batch 0040/0071 | Cost: 2.4820\n",
      "Epoch: 072/075 | Batch 0050/0071 | Cost: 2.2241\n",
      "Epoch: 072/075 | Batch 0060/0071 | Cost: 2.1735\n",
      "Epoch: 072/075 | Batch 0070/0071 | Cost: 2.4426\n",
      "MAE/RMSE: | Current Valid: 6.52/9.72/87.44 Ep. 71 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 38.66 min\n",
      "Epoch: 073/075 | Batch 0000/0071 | Cost: 2.4353\n",
      "Epoch: 073/075 | Batch 0010/0071 | Cost: 2.4868\n",
      "Epoch: 073/075 | Batch 0020/0071 | Cost: 2.0352\n",
      "Epoch: 073/075 | Batch 0030/0071 | Cost: 2.5849\n",
      "Epoch: 073/075 | Batch 0040/0071 | Cost: 2.6542\n",
      "Epoch: 073/075 | Batch 0050/0071 | Cost: 1.9921\n",
      "Epoch: 073/075 | Batch 0060/0071 | Cost: 2.8679\n",
      "Epoch: 073/075 | Batch 0070/0071 | Cost: 2.2034\n",
      "MAE/RMSE: | Current Valid: 6.38/9.38/87.22 Ep. 72 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 39.20 min\n",
      "Epoch: 074/075 | Batch 0000/0071 | Cost: 2.1827\n",
      "Epoch: 074/075 | Batch 0010/0071 | Cost: 1.9681\n",
      "Epoch: 074/075 | Batch 0020/0071 | Cost: 2.5419\n",
      "Epoch: 074/075 | Batch 0030/0071 | Cost: 2.1734\n",
      "Epoch: 074/075 | Batch 0040/0071 | Cost: 2.6300\n",
      "Epoch: 074/075 | Batch 0050/0071 | Cost: 2.3926\n",
      "Epoch: 074/075 | Batch 0060/0071 | Cost: 2.4193\n",
      "Epoch: 074/075 | Batch 0070/0071 | Cost: 3.0259\n",
      "MAE/RMSE: | Current Valid: 5.81/8.45/86.87 Ep. 73 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 39.74 min\n",
      "Epoch: 075/075 | Batch 0000/0071 | Cost: 2.5909\n",
      "Epoch: 075/075 | Batch 0010/0071 | Cost: 2.1758\n",
      "Epoch: 075/075 | Batch 0020/0071 | Cost: 2.2108\n",
      "Epoch: 075/075 | Batch 0030/0071 | Cost: 2.1038\n",
      "Epoch: 075/075 | Batch 0040/0071 | Cost: 2.1216\n",
      "Epoch: 075/075 | Batch 0050/0071 | Cost: 2.2241\n",
      "Epoch: 075/075 | Batch 0060/0071 | Cost: 2.3028\n",
      "Epoch: 075/075 | Batch 0070/0071 | Cost: 2.4919\n",
      "MAE/RMSE: | Current Valid: 5.76/8.39/87.79 Ep. 74 | Best Valid : 5.48/8.21/87.53 Ep. 51\n",
      "Time elapsed: 40.28 min\n",
      "MAE/RMSE: | Train: 1.09/1.92/95.75 | Valid: 5.76/8.39/87.79 | Test: 5.91/8.61/88.24\n",
      "Total Training Time: 40.86 min\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Initialize Cost, Model, and Optimizer\n",
    "###########################################\n",
    "def cost_fn(logits, levels, imp):\n",
    "    val = (-torch.sum((F.log_softmax(logits, dim=2)[:, :, 1]*levels\n",
    "                      + F.log_softmax(logits, dim=2)[:, :, 0]*(1-levels))*imp, dim=1))\n",
    "    return torch.mean(val)\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "model = resnet34(num_classes=117,grayscale=GRAYSCALE)\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "\n",
    "\n",
    "def compute_mae_and_mse(model, data_loader, device):\n",
    "    mae, mse, num_examples1, num_examples2, correct_pred = 0, 0, 0, 0, 0\n",
    "    for i, (features, target1, target2, levels) in enumerate(data_loader):\n",
    "\n",
    "        features = features.to(device)\n",
    "        target1 = target1.to(device)\n",
    "        target2 = target2.float().to(device)\n",
    "        logits1,logits2,probas1,probas2 = model(features)\n",
    "        \n",
    "        predict_levels = probas1 > 0.5\n",
    "        predictions = probas2 > 0.5\n",
    "        predicted_labels1 = torch.sum(predict_levels, dim=1)\n",
    "        predicted_labels2 = torch.sum(predictions, dim=1)\n",
    "        num_examples1 += target1.size(0)\n",
    "        num_examples2 += target2.size(0)\n",
    "        \n",
    "        mae += torch.sum(torch.abs(predicted_labels1 - target1))\n",
    "        mse += torch.sum((predicted_labels1 - target1)**2)\n",
    "        correct_pred += (predicted_labels2==target2).sum()\n",
    "    \n",
    "    mae = mae.float() / num_examples1\n",
    "    mse = mse.float() / num_examples1\n",
    "    gender_acc=correct_pred.float()/num_examples2*100\n",
    "    return mae, mse, gender_acc\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "best_mae, best_rmse, best_epoch = 999, 999, -1\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (features, target1, target2, levels) in enumerate(train_loader):\n",
    "        features = features.to(DEVICE)\n",
    "        target1 = target1.to(DEVICE)\n",
    "        target2 = target2.float().to(DEVICE)\n",
    "        levels = levels.to(DEVICE)\n",
    "\n",
    "        # FORWARD AND BACK PROP\n",
    "        logits1, logits2, probas1,probas2 = model(features)\n",
    "        cost1 = cost_fn(logits1,levels,imp)\n",
    "        demo = nn.BCELoss()\n",
    "        act = nn.Sigmoid()\n",
    "        cost2 = demo(act(logits2),target2.unsqueeze(1))\n",
    "        \n",
    "        cost=cost1+cost2\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cost.backward()\n",
    "\n",
    "        # UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "\n",
    "        # LOGGING\n",
    "        if not batch_idx % 10:\n",
    "            s = ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f'\n",
    "                 % (epoch+1, num_epochs, batch_idx,\n",
    "                     len(train_dataset)//BATCH_SIZE, cost))\n",
    "            print(s)\n",
    "            with open(LOGFILE, 'a') as f:\n",
    "                f.write('%s\\n' % s)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        valid_mae, valid_mse, valid_gender = compute_mae_and_mse(model, valid_loader,\n",
    "                                                   device=DEVICE)\n",
    "\n",
    "    if valid_mae < best_mae:\n",
    "        best_mae, best_rmse, best_gacc, best_epoch = valid_mae, torch.sqrt(valid_mse),valid_gender, epoch\n",
    "        ########## SAVE MODEL #############\n",
    "        torch.save(model.state_dict(), os.path.join(Path, 'best_model.pt'))\n",
    "\n",
    "    s='MAE/RMSE: | Current Valid: %.2f/%.2f/%.2f Ep. %d | Best Valid : %.2f/%.2f/%.2f Ep. %d' % (\n",
    "        valid_mae, torch.sqrt(valid_mse), valid_gender, epoch, best_mae, best_rmse, best_gacc, best_epoch)\n",
    "    print(s)\n",
    "    with open(LOGFILE, 'a') as f:\n",
    "        f.write('%s\\n' % s)\n",
    "\n",
    "    s = 'Time elapsed: %.2f min' % ((time.time() - start_time)/60)\n",
    "    print(s)\n",
    "    with open(LOGFILE, 'a') as f:\n",
    "        f.write('%s\\n' % s)\n",
    "\n",
    "model.eval()\n",
    "with torch.set_grad_enabled(False):  # save memory during inference\n",
    "\n",
    "    train_mae, train_mse, train_gender = compute_mae_and_mse(model, train_loader,\n",
    "                                               device=DEVICE)\n",
    "    valid_mae, valid_mse, valid_gender = compute_mae_and_mse(model, valid_loader,\n",
    "                                               device=DEVICE)\n",
    "    test_mae, test_mse, test_gender= compute_mae_and_mse(model, test_loader,\n",
    "                                             device=DEVICE)\n",
    "\n",
    "    s = 'MAE/RMSE: | Train: %.2f/%.2f/%.2f | Valid: %.2f/%.2f/%.2f | Test: %.2f/%.2f/%.2f' % (\n",
    "        train_mae, torch.sqrt(train_mse),train_gender,\n",
    "        valid_mae, torch.sqrt(valid_mse),valid_gender,\n",
    "        test_mae, torch.sqrt(test_mse),test_gender)\n",
    "    print(s)\n",
    "    with open(LOGFILE, 'a') as f:\n",
    "        f.write('%s\\n' % s)\n",
    "\n",
    "s = 'Total Training Time: %.2f min' % ((time.time() - start_time)/60)\n",
    "print(s)\n",
    "with open(LOGFILE, 'a') as f:\n",
    "    f.write('%s\\n' % s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3880ec8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T08:35:33.916834Z",
     "iopub.status.busy": "2023-08-08T08:35:33.916416Z",
     "iopub.status.idle": "2023-08-08T08:36:07.174802Z",
     "shell.execute_reply": "2023-08-08T08:36:07.173465Z"
    },
    "papermill": {
     "duration": 33.315494,
     "end_time": "2023-08-08T08:36:07.177890",
     "exception": false,
     "start_time": "2023-08-08T08:35:33.862396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE/RMSE: | Best Train: 1.70/2.63/93.94 | Best Valid: 5.48/8.21/87.53 | Best Test: 5.80/8.73/87.98\n"
     ]
    }
   ],
   "source": [
    "########## EVALUATE BEST MODEL ######\n",
    "model.load_state_dict(torch.load(os.path.join(Path, 'best_model.pt')))\n",
    "model.eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_mae, train_mse, train_gender = compute_mae_and_mse(model, train_loader,\n",
    "                                               device=DEVICE)\n",
    "    valid_mae, valid_mse ,valid_gender= compute_mae_and_mse(model, valid_loader,\n",
    "                                               device=DEVICE)\n",
    "    test_mae, test_mse, test_gender = compute_mae_and_mse(model, test_loader,\n",
    "                                             device=DEVICE)\n",
    "\n",
    "    s = 'MAE/RMSE: | Best Train: %.2f/%.2f/%.2f | Best Valid: %.2f/%.2f/%.2f | Best Test: %.2f/%.2f/%.2f' % (\n",
    "        train_mae, torch.sqrt(train_mse),train_gender,\n",
    "        valid_mae, torch.sqrt(valid_mse),valid_gender,\n",
    "        test_mae, torch.sqrt(test_mse), test_gender)\n",
    "    print(s)\n",
    "    with open(LOGFILE, 'a') as f:\n",
    "        f.write('%s\\n' % s)\n",
    "\n",
    "\n",
    "########## SAVE PREDICTIONS ######\n",
    "all_pred1 = []\n",
    "all_pred2 = []\n",
    "all_probas = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch_idx, (features, target1, target2, levels) in enumerate(test_loader):\n",
    "\n",
    "        features = features.to(DEVICE)\n",
    "        logits1,logits2,probas1,probas2 = model(features)\n",
    "        all_probas.append(probas1)\n",
    "        predict_levels = probas1 > 0.5\n",
    "        predictions = probas2 > 0.5\n",
    "        predicted_labels1 = torch.sum(predict_levels, dim=1)\n",
    "        predicted_labels2 = torch.sum(predictions, dim=1)\n",
    "        lst1 = [str(int(i)) for i in predicted_labels1]\n",
    "        lst2 = [str(int(j)) for j in predicted_labels2]\n",
    "        all_pred1.extend(lst1)\n",
    "        all_pred2.extend(lst2)\n",
    "\n",
    "torch.save(torch.cat(all_probas).to(torch.device('cpu')), TEST_ALLPROBAS)\n",
    "with open(TEST_PREDICTIONS1, 'w') as f:\n",
    "    all_pred1 = ','.join(all_pred1)\n",
    "    f.write(all_pred1)\n",
    "with open(TEST_PREDICTIONS2, 'w') as f:\n",
    "    all_pred2 = ','.join(all_pred2)\n",
    "    f.write(all_pred2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2503.168355,
   "end_time": "2023-08-08T08:36:09.064015",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-08T07:54:25.895660",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
